{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Hidden Markov Models (*HMMs*) for speech recognition\n",
    "\n",
    "We'll use *Gaussian HMMs* to model our data. *HMMs* are great tool for modeling time series data. As an audio signa is a time series signal, so the *HMMs* fit our needs. \n",
    "\n",
    "*HMMs* are popular because they can be trained automatically and are simple and computationally feasible to use. A *HMM* represent probability distrubutions over sequencs of observations.\n",
    "\n",
    "In this document we use **hmmlearn** package built with Sphinx and **python_speech features** built for MFCC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import wavfile \n",
    "from hmmlearn import hmm\n",
    "from python_speech_features import mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to handle HMM processing\n",
    "class HMMTrainer(object):  \n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    n_components: parameter defines the number of hidden states\n",
    "    cov_type: defines the type of covariance in transition matrix\n",
    "    n_iter: indicates the number of iterations for traning\n",
    "    \n",
    "    Choice of parameters depends on the data. \n",
    "    '''\n",
    "    def __init__(self, model_name='GaussianHMM', n_components=3, covariance_type=\"diag\",\n",
    "                 init_params=\"cm\", params=\"cmt\", n_iter=1000):\n",
    "        \n",
    "        # initialize\n",
    "        self.model_name = model_name\n",
    "        self.n_components = n_components\n",
    "        self.covariance_type = covariance_type\n",
    "        self.init_params = init_params\n",
    "        self.params = params\n",
    "        self.n_iter = n_iter\n",
    "        self.models = []\n",
    "\n",
    "\n",
    "        # define model\n",
    "        if self.model_name == 'GaussianHMM':\n",
    "            self.model = hmm.GaussianHMM(n_components=self.n_components,\n",
    "                                         covariance_type=self.covariance_type,\n",
    "                                         init_params=self.init_params, \n",
    "                                         params=self.params,\n",
    "                                         n_iter=self.n_iter)\n",
    "        else:\n",
    "            raise TypeError('Invalid model type')\n",
    "            \n",
    "            \n",
    "    # train data is 2D aray, where each frow is k-dimensions\n",
    "    def train(self, X):\n",
    "        \n",
    "        # ingonre divisin by 0\n",
    "        np.seterr(all='ignore')\n",
    "        self.models.append(self.model.fit(X))\n",
    "        \n",
    "    # run the model on input data and get score\n",
    "    def get_score(self, input_data):\n",
    "        return self.model.score(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need train data to build our speech recognizer. We will use the database available at [here](https://code.google.com/archive/p/hmm-speech-recognition/downloads). This data set contains seven different words, where each word has 15 audio files associated with it. We'll build an *HMM* model for each class by training our model on given dataset. Then after build model, given new input file, we need to run all the models on this file and pick the one with the best score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Anar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Anar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Anar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Anar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Anar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Anar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # init the variables of all HMM models\n",
    "    hmm_models = []\n",
    "    \n",
    "    # define train folder\n",
    "    dataset = 'train'\n",
    "    input_folder = 'data\\{}'.format(dataset)\n",
    "    \n",
    "    \n",
    "    # get path of input files\n",
    "    try:\n",
    "        audiofiles = os.listdir(input_folder)\n",
    "    except FileNotFoundError:\n",
    "        assert False, \"Folder not found\"\n",
    "\n",
    "    # pars the input directory that contains audio files\n",
    "    for dirname in audiofiles:\n",
    "        # get the name of the subfolder\n",
    "        subfolder = os.path.join(input_folder, dirname)\n",
    "        \n",
    "        if not os.path.isdir(subfolder):\n",
    "            continue    \n",
    "        \n",
    "        # extract the label\n",
    "        label = subfolder[subfolder.rfind('\\\\')+1:]\n",
    "\n",
    "        \n",
    "        # initialize intput variables and labels\n",
    "        X = np.array([])\n",
    "        y_words = []\n",
    "        \n",
    "        # iterate through the audio files\n",
    "        for filename in [x for x in os.listdir(subfolder) if x.endswith('.wav')]:\n",
    "            # Read the input file\n",
    "            filepath = os.path.join(subfolder, filename)\n",
    "            sampling_freq, audio = wavfile.read(filepath)\n",
    "            \n",
    "            # Extract MFCC features\n",
    "            mfcc_features = mfcc(audio, sampling_freq)\n",
    "\n",
    "            # Append to the variable X\n",
    "            if len(X) == 0:\n",
    "                X = mfcc_features\n",
    "            else:\n",
    "                X = np.append(X, mfcc_features, axis=0)\n",
    "            \n",
    "            # Append the label\n",
    "            y_words.append(label)\n",
    "            \n",
    "        \n",
    "        # Train and save HMM model\n",
    "#         print ('X.shape ='+ str(X.shape))\n",
    "        hmm_trainer = HMMTrainer()\n",
    "        hmm_trainer.train(X)\n",
    "        hmm_models.append((hmm_trainer, label))\n",
    "        hmm_trainer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After extracted features from all the files, train and save the HMM model.\n",
    "As HMM is a generative model for unsupervised learning, we don't need labels\n",
    "to build HMM modes for each class. We explitly assume that seperate HMM models\n",
    "will be built for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # define test folder\n",
    "    dataset = 'test'\n",
    "    input_folder = 'data\\{}'.format(dataset)\n",
    "    \n",
    "    # test folder\n",
    "    test_files = []\n",
    "\n",
    "    # get path of test files\n",
    "    try:\n",
    "        audiofiles = os.listdir(input_folder)\n",
    "    except FileNotFoundError:\n",
    "        assert False, \"Folder not found\"\n",
    "\n",
    "    # pars the input directory that contains audio files\n",
    "    for dirname in audiofiles:\n",
    "\n",
    "        # get the name of the subfolder\n",
    "        subfolder = os.path.join(input_folder, dirname)\n",
    "\n",
    "        if not os.path.isdir(subfolder):\n",
    "                continue\n",
    "\n",
    "        # iterate through the audio files\n",
    "        for filename in [x for x in os.listdir(subfolder) if x.endswith('.wav')]:\n",
    "            # read the input file\n",
    "\n",
    "            filepath = os.path.join(subfolder, filename)\n",
    "            test_files.append(filepath)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\test\\\\apple\\\\apple15.wav',\n",
       " 'data\\\\test\\\\banana\\\\banana15.wav',\n",
       " 'data\\\\test\\\\kiwi\\\\kiwi15.wav',\n",
       " 'data\\\\test\\\\lime\\\\lime15.wav',\n",
       " 'data\\\\test\\\\orange\\\\orange15.wav',\n",
       " 'data\\\\test\\\\peach\\\\peach15.wav',\n",
       " 'data\\\\test\\\\pineapple\\\\pineapple15.wav']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True: apple\n",
      "Predicted:apple\n",
      "\n",
      "True: banana\n",
      "Predicted:banana\n",
      "\n",
      "True: kiwi\n",
      "Predicted:kiwi\n",
      "\n",
      "True: lime\n",
      "Predicted:lime\n",
      "\n",
      "True: orange\n",
      "Predicted:orange\n",
      "\n",
      "True: peach\n",
      "Predicted:peach\n",
      "\n",
      "True: pineapple\n",
      "Predicted:pineapple\n"
     ]
    }
   ],
   "source": [
    "    # Classify input data\n",
    "    for input_file in test_files:\n",
    "        \n",
    "\n",
    "     \n",
    "\n",
    "        sampling_freq, audio = wavfile.read(input_file)\n",
    "        \n",
    "      \n",
    "\n",
    "        # Extract MFCC features\n",
    "        mfcc_features = mfcc(audio, sampling_freq)\n",
    "\n",
    "        # Define variables\n",
    "        max_score = hmm_models[0][0].get_score(mfcc_features)\n",
    "        output_label = None\n",
    "\n",
    "        # Iterate through all HMM models and pick \n",
    "        # the one with the highest score\n",
    "        for item in hmm_models:\n",
    "            hmm_model, label = item\n",
    "            score = hmm_model.get_score(mfcc_features)\n",
    "            if score >= max_score:\n",
    "                max_score = score\n",
    "                output_label = label\n",
    "                \n",
    "        print (\"\\nTrue: \" + input_file[input_file.find('\\\\')+6:input_file.rfind('\\\\')])\n",
    "        print (\"Predicted:\"+ str(output_label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
