{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building NN for speech recogniton and optimize result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "from python_speech_features import mfcc, logfbank\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spoken words: ['0_zero', '1_one', '2_two', '3_three', '4_four', '5_five', '6_six', '7_seven', '8_eight', '9_nine', 'aboard', 'adjusted & locked', 'All switches', 'Alternate air door', 'A_C Documents', 'Battery+Main bus', 'Cabin doors', 'Checked', 'Circuit Breakers', 'Closed', 'Cockpit', 'Cockpit checklist completed', 'Completed', 'decimal', 'Flight Controls', 'Fuel Quantity', 'Fuel Selector', 'Fuel Shutoff Valve', 'Fuel Temperature', 'in', 'locked', 'off', 'On', 'open', 'preflight_inspection', 'removed', 'Seats & Belts', 'Shut-off cabin heat', 'sufficient', 'Towbar', 'Weight and balance']\n"
     ]
    }
   ],
   "source": [
    "fpaths = []\n",
    "labels = []\n",
    "word_spoken = []\n",
    "\n",
    "\n",
    "dataset = '41'\n",
    "input_folder = 'data\\{}'.format(dataset)\n",
    "\n",
    "# pars the input directory that contains audio files\n",
    "# get audio files and their lables\n",
    "\n",
    "for f in os.listdir(input_folder):\n",
    "    for w in os.listdir(input_folder+'\\\\'+ f):\n",
    "        # check wheter files is wav or not\n",
    "        \n",
    "        if (w.find('wav')!=-1):\n",
    "            fpaths.append(input_folder+'\\\\'+f+'\\\\'+w)\n",
    "            labels.append(f)\n",
    "            if f not in word_spoken:\n",
    "                word_spoken.append(f)\n",
    "print(\"Spoken words: \"+ str(word_spoken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21433\n"
     ]
    }
   ],
   "source": [
    "# size of dataset\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting frequeny domain features\n",
    "\n",
    "At the second stage we convet a signal into the freqency domain. In monst modern speech recognitoon freqeency-domain features are used as key component. In case of multispeakers MFFC feature extraction works best. After convert a signal into a freq domain, it's requered to convert it into a useable form. **Mel Frequency Cepstral Coefficients (MFCC)** is a good way to do that. *MFCC* takes the power spectrum of a signal and then uses a combination of filter banks and disrete cosinetransform to extract pattern of phones or features.\n",
    "\n",
    "After extracting **MFFC** features we exract data into single data matrix, and a label vector with the correct label for eac data file is ceated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_zero\n",
      "1_one\n",
      "2_two\n",
      "3_three\n",
      "4_four\n",
      "5_five\n",
      "6_six\n",
      "7_seven\n",
      "8_eight\n",
      "9_nine\n",
      "aboard\n",
      "adjusted & locked\n",
      "All switches\n",
      "Alternate air door\n",
      "A_C Documents\n",
      "Battery+Main bus\n",
      "Cabin doors\n",
      "Checked\n",
      "Circuit Breakers\n",
      "Closed\n",
      "Cockpit\n",
      "Cockpit checklist completed\n",
      "Completed\n",
      "decimal\n",
      "Flight Controls\n",
      "Fuel Quantity\n",
      "Fuel Selector\n",
      "Fuel Shutoff Valve\n",
      "Fuel Temperature\n",
      "in\n",
      "locked\n",
      "off\n",
      "On\n",
      "open\n",
      "preflight_inspection\n",
      "removed\n",
      "Seats & Belts\n",
      "Shut-off cabin heat\n",
      "sufficient\n",
      "Towbar\n",
      "Weight and balance\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import wavfile\n",
    "\n",
    "data = []\n",
    "\n",
    "mfcc_max_length = 0\n",
    "\n",
    "# first file desitination name and index\n",
    "file_name = ''\n",
    "word_spoken_index = 0\n",
    "\n",
    "for n,file in enumerate(fpaths):\n",
    "    \n",
    "    # show current desintation \n",
    "    if (file.find(file_name)<=0):\n",
    "        file_name=word_spoken[word_spoken_index]\n",
    "        print(word_spoken[word_spoken_index])\n",
    "        word_spoken_index+=1\n",
    "\n",
    "    # read file \n",
    "    sampling_freq, audio = wavfile.read(file)\n",
    "    # Extract MFCC features\n",
    "    mfcc_features = mfcc(audio, sampling_freq)\n",
    "\n",
    "    \n",
    "    mfcc_len=mfcc_features.shape[0]*mfcc_features.shape[1]\n",
    "    # get length of largets feature array\n",
    "    if mfcc_len>mfcc_max_length:    \n",
    "        mfcc_max_length=mfcc_len\n",
    "     \n",
    "    # flat data into 2D array\n",
    "    mfcc_features=np.resize(mfcc_features,(1,mfcc_len))\n",
    "    \n",
    "    data.insert(n,mfcc_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pad zeros to small arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.zeros((len(data),mfcc_max_length), dtype=float)\n",
    "for i,_d in enumerate(data):\n",
    "    x_data[i,0:_d.shape[1]]=_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files total: 21433\n",
      "Labels and label indices [14 14 14 ... 31 31 31]\n"
     ]
    }
   ],
   "source": [
    "#Each sample file is one row in data, and has one entry in labels\n",
    "print('Number of files total:', len(data))\n",
    "all_labels = np.zeros(len(data),dtype=int)\n",
    "for n, l in enumerate(set(labels)):\n",
    "    all_labels[np.array([i for i, _ in enumerate(labels) if _ == l])] = n\n",
    "print('Labels and label indices', all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.zeros((len(all_labels),41),dtype=int)\n",
    "for i,_ in enumerate(all_labels):\n",
    "    target[i][_]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training matrix: (18218, 2808)\n",
      "Size of testing matrix: (3215, 2808)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.15, random_state=0)\n",
    "\n",
    "for train_index, test_index in sss.split(x_data,target):\n",
    "    X_train, X_test = x_data[train_index], x_data[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    \n",
    "\n",
    "print('Size of training matrix:', X_train.shape)\n",
    "print('Size of testing matrix:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize train\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize test\n",
    "scaler = preprocessing.StandardScaler().fit(X_test)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get number of columns in training data\n",
    "n_cols = x_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#add layers to model\n",
    "model.add(Dense(200, activation='sigmoid', input_shape=(n_cols,)))\n",
    "model.add(Dense(200, activation='sigmoid'))\n",
    "model.add(Dense(200, activation='sigmoid'))\n",
    "model.add(Dense(41, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 200)               561800    \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 41)                8241      \n",
      "=================================================================\n",
      "Total params: 650,441\n",
      "Trainable params: 650,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14574 samples, validate on 3644 samples\n",
      "Epoch 1/50\n",
      "14574/14574 [==============================] - 14s 955us/step - loss: 1.3543 - acc: 0.7305 - val_loss: 0.2554 - val_acc: 0.9608\n",
      "Epoch 2/50\n",
      "14574/14574 [==============================] - 13s 911us/step - loss: 0.1247 - acc: 0.9829 - val_loss: 0.0933 - val_acc: 0.9849\n",
      "Epoch 3/50\n",
      "14574/14574 [==============================] - 13s 871us/step - loss: 0.0363 - acc: 0.9962 - val_loss: 0.0707 - val_acc: 0.9846\n",
      "Epoch 4/50\n",
      "14574/14574 [==============================] - 13s 868us/step - loss: 0.0142 - acc: 0.9990 - val_loss: 0.0500 - val_acc: 0.9885\n",
      "Epoch 5/50\n",
      "14574/14574 [==============================] - 13s 873us/step - loss: 0.0069 - acc: 0.9996 - val_loss: 0.0490 - val_acc: 0.9877\n",
      "Epoch 6/50\n",
      "14574/14574 [==============================] - 13s 875us/step - loss: 0.0042 - acc: 0.9997 - val_loss: 0.0432 - val_acc: 0.9885\n",
      "Epoch 7/50\n",
      "14574/14574 [==============================] - 13s 882us/step - loss: 0.0028 - acc: 0.9999 - val_loss: 0.0448 - val_acc: 0.9887\n",
      "Epoch 8/50\n",
      "14574/14574 [==============================] - 13s 902us/step - loss: 0.0024 - acc: 0.9997 - val_loss: 0.0478 - val_acc: 0.9879\n",
      "Epoch 9/50\n",
      "14574/14574 [==============================] - 13s 899us/step - loss: 0.0013 - acc: 0.9999 - val_loss: 0.0541 - val_acc: 0.9855\n",
      "Epoch 10/50\n",
      "14574/14574 [==============================] - 13s 899us/step - loss: 0.0337 - acc: 0.9898 - val_loss: 0.0958 - val_acc: 0.9709\n",
      "Epoch 11/50\n",
      "14574/14574 [==============================] - 13s 897us/step - loss: 0.0140 - acc: 0.9962 - val_loss: 0.0659 - val_acc: 0.9794\n",
      "Epoch 12/50\n",
      "14574/14574 [==============================] - 14s 937us/step - loss: 0.0027 - acc: 0.9995 - val_loss: 0.0516 - val_acc: 0.9857\n",
      "Epoch 13/50\n",
      "14574/14574 [==============================] - 18s 1ms/step - loss: 6.0475e-04 - acc: 1.0000 - val_loss: 0.0463 - val_acc: 0.9852.3795e-04\n",
      "Epoch 14/50\n",
      "14574/14574 [==============================] - 16s 1ms/step - loss: 3.6863e-04 - acc: 1.0000 - val_loss: 0.0469 - val_acc: 0.9857\n",
      "Epoch 15/50\n",
      "14574/14574 [==============================] - 17s 1ms/step - loss: 2.7036e-04 - acc: 1.0000 - val_loss: 0.0466 - val_acc: 0.9860\n",
      "Epoch 16/50\n",
      "14574/14574 [==============================] - 15s 1ms/step - loss: 2.0093e-04 - acc: 1.0000 - val_loss: 0.0473 - val_acc: 0.9868\n",
      "Epoch 17/50\n",
      "14574/14574 [==============================] - 13s 899us/step - loss: 1.4790e-04 - acc: 1.0000 - val_loss: 0.0472 - val_acc: 0.9863\n",
      "Epoch 18/50\n",
      "14574/14574 [==============================] - 13s 898us/step - loss: 1.1292e-04 - acc: 1.0000 - val_loss: 0.0468 - val_acc: 0.9868\n",
      "Epoch 19/50\n",
      "14574/14574 [==============================] - 13s 911us/step - loss: 8.2781e-05 - acc: 1.0000 - val_loss: 0.0482 - val_acc: 0.9874\n",
      "Epoch 20/50\n",
      "14574/14574 [==============================] - 17s 1ms/step - loss: 5.9255e-05 - acc: 1.0000 - val_loss: 0.0489 - val_acc: 0.9879\n",
      "Epoch 21/50\n",
      "14574/14574 [==============================] - 15s 1ms/step - loss: 4.3276e-05 - acc: 1.0000 - val_loss: 0.0487 - val_acc: 0.9879\n",
      "Epoch 22/50\n",
      "14574/14574 [==============================] - 16s 1ms/step - loss: 3.0509e-05 - acc: 1.0000 - val_loss: 0.0489 - val_acc: 0.9879\n",
      "Epoch 23/50\n",
      "14574/14574 [==============================] - 15s 1ms/step - loss: 2.1740e-05 - acc: 1.0000 - val_loss: 0.0501 - val_acc: 0.9882\n",
      "Epoch 24/50\n",
      "14574/14574 [==============================] - 17s 1ms/step - loss: 1.5627e-05 - acc: 1.0000 - val_loss: 0.0520 - val_acc: 0.9879\n",
      "Epoch 25/50\n",
      "14574/14574 [==============================] - 15s 1ms/step - loss: 1.3151e-05 - acc: 1.0000 - val_loss: 0.0537 - val_acc: 0.9885\n",
      "Epoch 26/50\n",
      "14574/14574 [==============================] - 18s 1ms/step - loss: 0.0414 - acc: 0.9869 - val_loss: 0.0935 - val_acc: 0.9764\n",
      "Epoch 27/50\n",
      "14574/14574 [==============================] - 18s 1ms/step - loss: 0.0053 - acc: 0.9983 - val_loss: 0.0708 - val_acc: 0.9822\n",
      "Epoch 28/50\n",
      "14574/14574 [==============================] - 15s 1ms/step - loss: 7.2620e-04 - acc: 0.9999 - val_loss: 0.0606 - val_acc: 0.9877\n",
      "Epoch 29/50\n",
      "14574/14574 [==============================] - 15s 1ms/step - loss: 1.7002e-04 - acc: 1.0000 - val_loss: 0.0603 - val_acc: 0.9877\n",
      "Epoch 30/50\n",
      "14574/14574 [==============================] - 14s 970us/step - loss: 1.0513e-04 - acc: 1.0000 - val_loss: 0.0600 - val_acc: 0.9882\n",
      "Epoch 31/50\n",
      "14574/14574 [==============================] - 15s 1ms/step - loss: 7.6607e-05 - acc: 1.0000 - val_loss: 0.0604 - val_acc: 0.9879\n",
      "Epoch 32/50\n",
      "14574/14574 [==============================] - 16s 1ms/step - loss: 5.7100e-05 - acc: 1.0000 - val_loss: 0.0604 - val_acc: 0.9882\n",
      "Epoch 33/50\n",
      "14574/14574 [==============================] - 12s 847us/step - loss: 4.3105e-05 - acc: 1.0000 - val_loss: 0.0605 - val_acc: 0.9882\n",
      "Epoch 34/50\n",
      "14574/14574 [==============================] - 14s 984us/step - loss: 3.2703e-05 - acc: 1.0000 - val_loss: 0.0609 - val_acc: 0.9877\n",
      "Epoch 35/50\n",
      "14574/14574 [==============================] - 15s 1ms/step - loss: 2.4926e-05 - acc: 1.0000 - val_loss: 0.0610 - val_acc: 0.9877\n",
      "Epoch 36/50\n",
      "14574/14574 [==============================] - 17s 1ms/step - loss: 1.8995e-05 - acc: 1.0000 - val_loss: 0.0611 - val_acc: 0.9882\n",
      "Epoch 37/50\n",
      "14574/14574 [==============================] - 16s 1ms/step - loss: 1.4589e-05 - acc: 1.0000 - val_loss: 0.0617 - val_acc: 0.9879E\n",
      "Epoch 38/50\n",
      "14574/14574 [==============================] - 12s 822us/step - loss: 1.1079e-05 - acc: 1.0000 - val_loss: 0.0606 - val_acc: 0.9885 \n",
      "Epoch 39/50\n",
      "14574/14574 [==============================] - 12s 825us/step - loss: 8.4613e-06 - acc: 1.0000 - val_loss: 0.0614 - val_acc: 0.9885\n",
      "Epoch 40/50\n",
      "14574/14574 [==============================] - 15s 1ms/step - loss: 6.4439e-06 - acc: 1.0000 - val_loss: 0.0617 - val_acc: 0.9887\n",
      "Epoch 41/50\n",
      "14574/14574 [==============================] - 14s 929us/step - loss: 4.8293e-06 - acc: 1.0000 - val_loss: 0.0616 - val_acc: 0.9890\n",
      "Epoch 42/50\n",
      "14574/14574 [==============================] - 13s 913us/step - loss: 3.5547e-06 - acc: 1.0000 - val_loss: 0.0617 - val_acc: 0.9890\n",
      "Epoch 43/50\n",
      "14574/14574 [==============================] - 14s 960us/step - loss: 2.7007e-06 - acc: 1.0000 - val_loss: 0.0629 - val_acc: 0.9885\n",
      "Epoch 44/50\n",
      "14574/14574 [==============================] - 14s 985us/step - loss: 2.0206e-06 - acc: 1.0000 - val_loss: 0.0636 - val_acc: 0.9885\n",
      "Epoch 45/50\n",
      "14574/14574 [==============================] - 14s 950us/step - loss: 1.6973e-06 - acc: 1.0000 - val_loss: 0.0637 - val_acc: 0.9882\n",
      "Epoch 46/50\n",
      "14574/14574 [==============================] - 16s 1ms/step - loss: 1.0645e-06 - acc: 1.0000 - val_loss: 0.0639 - val_acc: 0.9893\n",
      "Epoch 47/50\n",
      "14574/14574 [==============================] - 17s 1ms/step - loss: 7.7892e-07 - acc: 1.0000 - val_loss: 0.0640 - val_acc: 0.9890\n",
      "Epoch 48/50\n",
      "14574/14574 [==============================] - 18s 1ms/step - loss: 5.9141e-07 - acc: 1.0000 - val_loss: 0.0640 - val_acc: 0.9893\n",
      "Epoch 49/50\n",
      "14574/14574 [==============================] - 16s 1ms/step - loss: 4.6002e-07 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9887\n",
      "Epoch 50/50\n",
      "14574/14574 [==============================] - 16s 1ms/step - loss: 3.6304e-07 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x233c49abf28>"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=20,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 98.44%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
