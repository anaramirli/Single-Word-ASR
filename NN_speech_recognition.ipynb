{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building NN for speech recogniton and optimize result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "from python_speech_features import mfcc, logfbank\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from keras.models import Sequential\n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "features_df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train label and data\n",
    "all_labels = features_df.values[:,0]\n",
    "x_data = features_df.values[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare categorical target values (e.g [0,0,0,1,0])\n",
    "target = np.zeros((len(all_labels),41),dtype=int)\n",
    "for i,_ in enumerate(all_labels):\n",
    "    target[i][int(_)]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training matrix: (18217, 2808)\n",
      "Size of testing matrix: (3215, 2808)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.15, random_state=0)\n",
    "\n",
    "for train_index, test_index in sss.split(x_data,target):\n",
    "    X_train, X_test = x_data[train_index], x_data[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    \n",
    "\n",
    "print('Size of training matrix:', X_train.shape)\n",
    "print('Size of testing matrix:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize train\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize test\n",
    "scaler = preprocessing.StandardScaler().fit(X_test)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get number of columns in training data\n",
    "n_cols = x_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#add layers to model\n",
    "model.add(Dense(200, activation='sigmoid', input_shape=(n_cols,)))\n",
    "model.add(Dense(200, activation='sigmoid'))\n",
    "model.add(Dense(41, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 200)               561800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 41)                8241      \n",
      "=================================================================\n",
      "Total params: 610,241\n",
      "Trainable params: 610,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model parameters\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14573 samples, validate on 3644 samples\n",
      "Epoch 1/50\n",
      "14573/14573 [==============================] - 15s 1ms/step - loss: 0.9201 - acc: 0.8698 - val_loss: 0.1718 - val_acc: 0.9797\n",
      "Epoch 2/50\n",
      "14573/14573 [==============================] - 15s 1ms/step - loss: 0.0869 - acc: 0.9907 - val_loss: 0.0867 - val_acc: 0.9879\n",
      "Epoch 3/50\n",
      "14573/14573 [==============================] - 15s 1ms/step - loss: 0.0295 - acc: 0.9980 - val_loss: 0.0615 - val_acc: 0.9893\n",
      "Epoch 4/50\n",
      "14573/14573 [==============================] - 13s 879us/step - loss: 0.0128 - acc: 0.9995 - val_loss: 0.0553 - val_acc: 0.9907\n",
      "Epoch 5/50\n",
      "14573/14573 [==============================] - 13s 922us/step - loss: 0.0068 - acc: 0.9997 - val_loss: 0.0496 - val_acc: 0.9896\n",
      "Epoch 6/50\n",
      "14573/14573 [==============================] - 16s 1ms/step - loss: 0.0042 - acc: 0.9998 - val_loss: 0.0484 - val_acc: 0.9909s: 0.0059 - acc: - ETA: - ETA: 5s - loss: 0.004\n",
      "Epoch 7/50\n",
      "14573/14573 [==============================] - 15s 1ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0468 - val_acc: 0.9912\n",
      "Epoch 8/50\n",
      "14573/14573 [==============================] - 15s 1ms/step - loss: 0.0019 - acc: 0.9997 - val_loss: 0.0502 - val_acc: 0.9904\n",
      "Epoch 9/50\n",
      "14573/14573 [==============================] - 13s 919us/step - loss: 0.0016 - acc: 0.9998 - val_loss: 0.0494 - val_acc: 0.9901\n",
      "Epoch 10/50\n",
      "14573/14573 [==============================] - 16s 1ms/step - loss: 7.0586e-04 - acc: 0.9999 - val_loss: 0.0472 - val_acc: 0.9901\n",
      "Epoch 11/50\n",
      "14573/14573 [==============================] - 17s 1ms/step - loss: 3.4370e-04 - acc: 1.0000 - val_loss: 0.0482 - val_acc: 0.9901\n",
      "Epoch 12/50\n",
      "14573/14573 [==============================] - 18s 1ms/step - loss: 2.4045e-04 - acc: 1.0000 - val_loss: 0.0492 - val_acc: 0.9901\n",
      "Epoch 13/50\n",
      "14573/14573 [==============================] - 15s 1ms/step - loss: 1.6647e-04 - acc: 1.0000 - val_loss: 0.0491 - val_acc: 0.9898\n",
      "Epoch 14/50\n",
      "14573/14573 [==============================] - 14s 992us/step - loss: 1.1522e-04 - acc: 1.0000 - val_loss: 0.0488 - val_acc: 0.9907\n",
      "Epoch 15/50\n",
      "14573/14573 [==============================] - 16s 1ms/step - loss: 8.2928e-05 - acc: 1.0000 - val_loss: 0.0508 - val_acc: 0.9912\n",
      "Epoch 16/50\n",
      "14573/14573 [==============================] - 17s 1ms/step - loss: 0.0255 - acc: 0.9918 - val_loss: 0.0733 - val_acc: 0.9857\n",
      "Epoch 17/50\n",
      "14573/14573 [==============================] - 14s 992us/step - loss: 0.0078 - acc: 0.9982 - val_loss: 0.0573 - val_acc: 0.9863\n",
      "Epoch 18/50\n",
      "14573/14573 [==============================] - 16s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0541 - val_acc: 0.9893\n",
      "Epoch 19/50\n",
      "14573/14573 [==============================] - 17s 1ms/step - loss: 3.3704e-04 - acc: 1.0000 - val_loss: 0.0534 - val_acc: 0.9893\n",
      "Epoch 20/50\n",
      "14573/14573 [==============================] - 17s 1ms/step - loss: 2.4133e-04 - acc: 1.0000 - val_loss: 0.0530 - val_acc: 0.9901- ETA: 3s - loss: 2.4832e-04 - acc:\n",
      "Epoch 21/50\n",
      "14573/14573 [==============================] - 16s 1ms/step - loss: 1.9055e-04 - acc: 1.0000 - val_loss: 0.0527 - val_acc: 0.9904- ETA: 0s - loss: 1.9158e-04 - acc:\n",
      "Epoch 22/50\n",
      "14573/14573 [==============================] - 17s 1ms/step - loss: 1.3370e-04 - acc: 1.0000 - val_loss: 0.0539 - val_acc: 0.9907: 1s - \n",
      "Epoch 23/50\n",
      "14573/14573 [==============================] - 16s 1ms/step - loss: 9.7904e-05 - acc: 1.0000 - val_loss: 0.0538 - val_acc: 0.9901\n",
      "Epoch 24/50\n",
      "14573/14573 [==============================] - 15s 1ms/step - loss: 7.3731e-05 - acc: 1.0000 - val_loss: 0.0537 - val_acc: 0.9904\n",
      "Epoch 25/50\n",
      "14573/14573 [==============================] - 15s 1ms/step - loss: 5.5698e-05 - acc: 1.0000 - val_loss: 0.0547 - val_acc: 0.9907TA: 1s - loss: 5.6\n",
      "Epoch 26/50\n",
      "14573/14573 [==============================] - 14s 941us/step - loss: 4.2501e-05 - acc: 1.0000 - val_loss: 0.0542 - val_acc: 0.9907\n",
      "Epoch 27/50\n",
      "14573/14573 [==============================] - 14s 959us/step - loss: 3.0637e-05 - acc: 1.0000 - val_loss: 0.0539 - val_acc: 0.9901\n",
      "Epoch 28/50\n",
      "14573/14573 [==============================] - 13s 879us/step - loss: 2.2571e-05 - acc: 1.0000 - val_loss: 0.0567 - val_acc: 0.9907\n",
      "Epoch 29/50\n",
      "14573/14573 [==============================] - 14s 946us/step - loss: 1.6248e-05 - acc: 1.0000 - val_loss: 0.0552 - val_acc: 0.9907\n",
      "Epoch 30/50\n",
      "14573/14573 [==============================] - 14s 928us/step - loss: 1.1360e-05 - acc: 1.0000 - val_loss: 0.0555 - val_acc: 0.9907\n",
      "Epoch 31/50\n",
      "14573/14573 [==============================] - 15s 995us/step - loss: 8.1446e-06 - acc: 1.0000 - val_loss: 0.0559 - val_acc: 0.9907\n",
      "Epoch 32/50\n",
      "14573/14573 [==============================] - 14s 948us/step - loss: 5.8249e-06 - acc: 1.0000 - val_loss: 0.0568 - val_acc: 0.9904\n",
      "Epoch 33/50\n",
      "14573/14573 [==============================] - 13s 879us/step - loss: 4.1680e-06 - acc: 1.0000 - val_loss: 0.0575 - val_acc: 0.9907\n",
      "Epoch 34/50\n",
      "14573/14573 [==============================] - 13s 896us/step - loss: 2.9653e-06 - acc: 1.0000 - val_loss: 0.0578 - val_acc: 0.9904\n",
      "Epoch 35/50\n",
      "14573/14573 [==============================] - 15s 1000us/step - loss: 2.1211e-06 - acc: 1.0000 - val_loss: 0.0587 - val_acc: 0.9901\n",
      "Epoch 36/50\n",
      "14573/14573 [==============================] - 15s 1ms/step - loss: 1.5374e-06 - acc: 1.0000 - val_loss: 0.0587 - val_acc: 0.9901\n",
      "Epoch 37/50\n",
      "14573/14573 [==============================] - 14s 962us/step - loss: 1.1055e-06 - acc: 1.0000 - val_loss: 0.0592 - val_acc: 0.9901\n",
      "Epoch 38/50\n",
      "14573/14573 [==============================] - 14s 935us/step - loss: 8.0825e-07 - acc: 1.0000 - val_loss: 0.0598 - val_acc: 0.9898\n",
      "Epoch 39/50\n",
      "14573/14573 [==============================] - 13s 872us/step - loss: 5.9739e-07 - acc: 1.0000 - val_loss: 0.0611 - val_acc: 0.9901\n",
      "Epoch 40/50\n",
      "14573/14573 [==============================] - 14s 963us/step - loss: 4.7718e-07 - acc: 1.0000 - val_loss: 0.0605 - val_acc: 0.9907\n",
      "Epoch 41/50\n",
      "14573/14573 [==============================] - 14s 932us/step - loss: 3.6307e-07 - acc: 1.0000 - val_loss: 0.0615 - val_acc: 0.9898\n",
      "Epoch 42/50\n",
      "14573/14573 [==============================] - 14s 947us/step - loss: 2.8917e-07 - acc: 1.0000 - val_loss: 0.0615 - val_acc: 0.9901\n",
      "Epoch 43/50\n",
      "14573/14573 [==============================] - 14s 963us/step - loss: 2.4187e-07 - acc: 1.0000 - val_loss: 0.0618 - val_acc: 0.9898- loss: \n",
      "Epoch 44/50\n",
      "14573/14573 [==============================] - 14s 956us/step - loss: 2.0870e-07 - acc: 1.0000 - val_loss: 0.0626 - val_acc: 0.9898\n",
      "Epoch 45/50\n",
      "14573/14573 [==============================] - 14s 945us/step - loss: 1.8546e-07 - acc: 1.0000 - val_loss: 0.0630 - val_acc: 0.9898\n",
      "Epoch 46/50\n",
      "14573/14573 [==============================] - 13s 914us/step - loss: 1.6856e-07 - acc: 1.0000 - val_loss: 0.0629 - val_acc: 0.9898\n",
      "Epoch 47/50\n",
      "14573/14573 [==============================] - 14s 979us/step - loss: 1.5678e-07 - acc: 1.0000 - val_loss: 0.0632 - val_acc: 0.9898\n",
      "Epoch 48/50\n",
      "14573/14573 [==============================] - 13s 864us/step - loss: 1.4795e-07 - acc: 1.0000 - val_loss: 0.0634 - val_acc: 0.9898\n",
      "Epoch 49/50\n",
      "14573/14573 [==============================] - 14s 941us/step - loss: 1.4180e-07 - acc: 1.0000 - val_loss: 0.0637 - val_acc: 0.98987 - acc: 1.00\n",
      "Epoch 50/50\n",
      "14573/14573 [==============================] - 13s 890us/step - loss: 1.3708e-07 - acc: 1.0000 - val_loss: 0.0640 - val_acc: 0.9898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2479cfbfcf8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=20,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 98.79%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall unseen test accuracy: 98.38 percent\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "how to evaluate evaluate model:\n",
    "    select the ones with larget prob.\n",
    "    if prob of ones are euqal for any model then select the model with min others prob\n",
    "'''\n",
    "\n",
    "predicted_label = np.argmax(y_test, axis=1)\n",
    " \n",
    "result=np.zeros((y_test.shape[0]), dtype=int)\n",
    "\n",
    "for i in range(y_test.shape[0]):\n",
    "    max_array=[]\n",
    "    max_n=-100\n",
    "    idx=0\n",
    "    for j in range(41):\n",
    "        max_array.append(prob[i][j])\n",
    "        \n",
    "        if prob[i][j]>max_n and prob[i][j]>=0.9:\n",
    "            max_n=prob[i][j]\n",
    "            idx=j   \n",
    "       \n",
    "    #sort max array\n",
    "    max_array.sort()\n",
    "    \n",
    "    # compare result with the actual labels\n",
    "    if(int(predicted_label[i])==int(idx) and max_array[-1]-max_array[-2]>=0.5):\n",
    "        result[i]=1\n",
    "        \n",
    "        \n",
    "overall_acc = np.mean(result)*100\n",
    "print('Overall unseen test accuracy: %.2f percent' % overall_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy on unseen test data (normal model)**\n",
    "\n",
    "* Normal Accuracy: 98.79\n",
    "\n",
    "* Accuracy where (h1>=0.9): 98.38\n",
    "\n",
    "* Accuracy where (h1>=0.9 and h2-h2>=0.5): 98.38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=[[3,3,3,5,5,2],[12434,7,4,3,2,6]]\n",
    "d=np.array(d)\n",
    "predicted_label = np.argmax(d, axis=1)\n",
    "predicted_label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
