{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "from python_speech_features import mfcc, logfbank\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name=\"1_all_NNs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "train_df = pd.read_csv('data/ADA_girl_boy/data41ADA_girl.csv')\n",
    "test_df = pd.read_csv('data/ADA_girl_boy/data41ADA_boy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test and train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     \"\"\"\n",
    "#     get data and return preprocessed data\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     train_df: train data\n",
    "#     test_df: test data\n",
    "#     label_increment: increment model index only for one vs. all models, default False\n",
    "#     categorical: categorical preperation of data, default True\n",
    "#     category_size: category size for catageorical preperation, default: 41\n",
    "#     normalize: normalize data, default True;\n",
    "    \n",
    "#     Return\n",
    "#     ------\n",
    "#     X_out, y_out\n",
    "#     \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type: no_category, yes_incement\n",
    "X_train, y_train = utils_prepare_data(train_df, label_increment=True, categorical=False)\n",
    "X_test, y_test = utils_prepare_data(test_df, label_increment=True, categorical=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Size of training matrix:', X_train.shape)\n",
    "print('Size of testing matrix:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique labesl\n",
    "unique_words = set(y_train)\n",
    "print(unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMBALANCED DATASET\n",
    "In this document we train our model by utilizing one vs all apprach. Thefore the data of single label (ones) is considerably low than that of others. Before train our model, we need to fix the imbalance dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw chart\n",
    "def pie_chart(y,label):\n",
    "    one_shape = y[y==label].shape[0]\n",
    "    others_shape = y[y!=label].shape[0]\n",
    "    plt.pie(\n",
    "        list([one_shape, others_shape]),\n",
    "        labels=['Label {}: {}'.format(label,one_shape),'{}: {}'.format('others',others_shape)]\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize imbalanced dataset: exmaple for label 1\n",
    "pie_chart(y_train,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE\n",
    "SMOTE (Synthetic Minority Over-Sampling Technique) is an over-sampling technique that introduces small perturbations to synthetic examples along the direction of existing samples to reduce overfitting. See original paper for detailed explanation of SMOTE.\n",
    "\n",
    "\n",
    "#### SMOTE Implementation\n",
    "\n",
    "There is a SMOTE implementation in imblearn package for scikit-learn. However, there is not an option to apply SMOTE with arbitrary percentages (SMOTE-100, SMOTE-300, etc.); it simply balances all the classes. And also since SMOTE is not a hard to implement algorithm, we provide our own implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from random import randint\n",
    "\n",
    "\n",
    "def smote(samples, amount, k=5):\n",
    "    \"\"\"\n",
    "    Apply SMOTE algorithm to samples and return a new samples\n",
    "    array with synthetically created samples.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    samples: (n_samples, n_features) samples array to be sent to\n",
    "             SMOTE algorithm.\n",
    "    amount: Percentage of newly created synthetic samples. (E.g.\n",
    "            amount=100 would create as many synthetic examples\n",
    "            as existing ones).\n",
    "    k: Number of nearest neighbors in SMOTE algorithm.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    out: ((1 + amount/100)*n_samples, n_features) samples array containing\n",
    "         the original and the newly created synthetic examples.\n",
    "         \n",
    "    References\n",
    "    ----------\n",
    "    http://www.jair.org/media/953/live-953-2037-jair.pdf\n",
    "    \"\"\"\n",
    "    samples = np.copy(samples)\n",
    "    n_samples, n_features = samples.shape\n",
    "    # handle amount < 100 case\n",
    "    if amount < 100:\n",
    "        num_samples = int(len(samples)*(amount/100))\n",
    "        np.shuffle(samples)\n",
    "        samples = samples[:num_samples, :]\n",
    "        amount = 100\n",
    "    amount = int(amount/100)\n",
    "    synthetic = np.empty((n_samples*amount, n_features))\n",
    "    # find k nearest neighbors of each point and store it in nnarray\n",
    "    nbrs = NearestNeighbors(n_neighbors=k + 1).fit(samples)\n",
    "    _, nnarray = nbrs.kneighbors(samples)\n",
    "    nnarray = nnarray[:, 1:]  # get rid of self-nearest-neighbor.\n",
    "    # create synthetic examples and store them in synthetic.\n",
    "    for i, neighbors in enumerate(nnarray):\n",
    "        for j in range(amount):\n",
    "            chosen = neighbors[randint(0, k - 1)]\n",
    "            diff = samples[chosen] - samples[i]\n",
    "            gap = np.random.rand(n_features)\n",
    "            synthetic[i*amount + j] = samples[i] + gap*diff\n",
    "    out = np.vstack((samples, synthetic))\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing Synthetic SMOTE Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sample array\n",
    "arr1 = np.random.normal(loc=5, scale=2.5, size=(50, 2))\n",
    "arr2 = np.random.normal(loc=0, scale=2.5, size=(20, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_smote = smote(arr2, 100)\n",
    "plt.scatter(*arr1.T, label='Majority')\n",
    "plt.scatter(*arr2.T, label='Minority')\n",
    "plt.scatter(*arr_smote[25:, :].T, label='new SMOTE samples')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote_sampling(X, y, label):\n",
    "\n",
    "    other_n = y[y!=label].shape[0]\n",
    "    one_n = y[y==label].shape[0]\n",
    "    smote_amount = int(((other_n-one_n)*100)/one_n)\n",
    "\n",
    "    X_one = X[y==label]\n",
    "    synthetic_data = smote(X_one, smote_amount)\n",
    "    n_synthetic = len(synthetic_data)\n",
    "\n",
    "    # merge synthetic examples with original examples\n",
    "    X_out = np.vstack((X[y!=label], synthetic_data))\n",
    "    y_out = np.concatenate((y[y!=label], [label]*n_synthetic))\n",
    "\n",
    "    return X_out, y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example for label 1 after upsampling\n",
    "X_out, y_out = smote_sampling(X_train, y_train, 1)\n",
    "pie_chart(y_out,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ronadom_undersample(X,y,label):\n",
    "    X1 = X[y==label]\n",
    "    y1 = y[y==label]\n",
    "\n",
    "    # define others labels\n",
    "    # and reduce theri elements randomly\n",
    "    X2 = X[y!=label]\n",
    "    y2 = y[y!=label]\n",
    "    idx = np.random.choice(np.arange(X2.shape[0]), int(X1.shape[0]*4), replace=False)\n",
    "    X2_new = X2[idx,:]\n",
    "    y2_new = y2[idx]\n",
    "\n",
    "    X_out = np.vstack((X1, X2_new))\n",
    "    y_out = np.concatenate((y1, y2_new))\n",
    "\n",
    "    return X_out, y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example for label 1 after undersampling\n",
    "X_out, y_out = ronadom_undersample(X_train, y_train, 1)\n",
    "pie_chart(y_out,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_oversmaple(X,y,label):\n",
    "    \n",
    "    X1 = X[y==label]\n",
    "    y1 = y[y==label]\n",
    "\n",
    "    # define others labels\n",
    "    # and reduce theri elements randomly\n",
    "    X2 = X[y!=label]\n",
    "    y2 = y[y!=label]\n",
    "    \n",
    "    X1_new=[X1]*int(X2.shape[0]/X1.shape[0])\n",
    "    X1_new=np.array(X1_new)\n",
    "    X1_new=np.resize(X1_new,(X1_new.shape[0]*X1_new.shape[1],X2.shape[1]))\n",
    "    \n",
    "    y1_new=[y1]*int(y2.shape[0]/y1.shape[0])\n",
    "    y1_new=np.array(y1_new)\n",
    "    y1_new=np.resize(y1_new,(y1_new.shape[0]*y1_new.shape[1]))\n",
    "                     \n",
    "                     \n",
    "    X_out = np.vstack((X1_new, X2))\n",
    "    y_out = np.concatenate((y1_new, y2))\n",
    "\n",
    "    return X_out, y_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINER CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to handle NN processing\n",
    "class NNTrainer(object):  \n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    layer_activation: activation function for input and hidden layers\n",
    "    covariance_type: activation function of end layer\n",
    "    input_n_cols: numver of columns of input layer\n",
    "    optimizer_function: optimization function\n",
    "    loss_function: loss functions\n",
    "    metrics_v: metric for evaluation result\n",
    "    epochs_n: number of epoches to update train weights\n",
    "    batch_size_n: batch size of fitted data\n",
    "    validation_split_n: ratio of validation split in traning \n",
    "    \n",
    "    choice of parameters depends on the data. \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, layer_activation='relu', end_layer_activation='softmax',input_n_cols=2808,\n",
    "                 optimizer_function='adam',loss_function='categorical_crossentropy',metrics_v='accuracy',\n",
    "                epochs_n=20, batch_size_n=20, validation_split_n=0.2):\n",
    "        \n",
    "        # initialize variables\n",
    "        self.layer_activation = layer_activation\n",
    "        self.end_layer_activation = end_layer_activation\n",
    "        self.input_n_cols = input_n_cols\n",
    "        self.optimizer_function = optimizer_function\n",
    "        self.loss_function = loss_function\n",
    "        self.metrics_v = metrics_v\n",
    "        self.epochs_n = epochs_n\n",
    "        self.batch_size_n =batch_size_n\n",
    "        self.validation_split_n = validation_split_n\n",
    "        \n",
    "        \n",
    "        # define model\n",
    "        self.model = Sequential()\n",
    "        #add layers to model and initialize\n",
    "        self.model.add(Dense(200, activation=self.layer_activation, input_shape=(self.input_n_cols,)))\n",
    "        self.model.add(Dense(200, activation=self.layer_activation, input_shape=(self.input_n_cols,)))\n",
    "        self.model.add(Dense(200, activation=self.layer_activation))\n",
    "#         self.model.add(Dropout(0.2))\n",
    "#         self.model.add(Dense(50, activation=self.layer_activation))\n",
    "        self.model.add(Dense(2, activation=self.end_layer_activation))\n",
    "        \n",
    "        # compile model\n",
    "        self.model.compile(optimizer=self.optimizer_function, \n",
    "                           loss=self.loss_function,metrics=[self.metrics_v])\n",
    "            \n",
    "    #train mode\n",
    "    def train(self, X_train, y_train):\n",
    "        # ingonre divisin by 0\n",
    "        # np.seterr(all='ignore') \n",
    "        #train model\n",
    "        self.model.fit(X_train, y_train, epochs=self.epochs_n,\n",
    "                       batch_size=self.batch_size_n,validation_split=self.validation_split_n)\n",
    "         \n",
    "    # run the model on new data and get score\n",
    "    def predict_probability(self, X_test):\n",
    "        scores = self.model.predict_proba(X_test)\n",
    "        return scores\n",
    "\n",
    "    \n",
    "    # return model\n",
    "    def model_evaluate(self, X_test, y_test):\n",
    "        scores = self.model.evaluate(X_test, y_test, verbose=0)\n",
    "        return scores[1]*100\n",
    "    \n",
    "    # return model\n",
    "    def get_nn_model():\n",
    "        return self.model\n",
    "    \n",
    "    def save_modle(self, folder_name, model_name):\n",
    "        # Creates a HDF5 file 'my_model.h5'\n",
    "        self.model.save('models/{path}/{model}.h5'.format(path=folder_name,model=model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN MODELS\n",
    "\n",
    "Train each model seperately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_t_data=[]\n",
    "# y_t_data=[]\n",
    "\n",
    "# for label in unique_words:\n",
    "    \n",
    "#     # random undersampling \n",
    "#     # X_out, y_out = ronadom_undersample(X_train, y_train, int(label))\n",
    "    \n",
    "#     # oversmapling smote\n",
    "#     # X_out,y_out = smote_sampling(X_train, y_train, int(label))\n",
    "    \n",
    "#     print(label)\n",
    "    \n",
    "#     # oversampling multiply\n",
    "#     X_out, y_out = multiply_oversmaple(X_train, y_train, int(label))\n",
    "    \n",
    "#     # shullfe data\n",
    "    \n",
    "#     time.sleep(30)\n",
    "    \n",
    "#     print(\"shuffle\")\n",
    "    \n",
    "#     X_out, y_out = shuffle(X_out, y_out, random_state=0)\n",
    "    \n",
    "#     X_t_data.insert(int(label)-1,X_out)\n",
    "#     y_t_data.insert(int(label)-1,y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn_models = [] # list to keep all models\n",
    "input_n_cols=X_train.shape[1]\n",
    "\n",
    "### for each model\n",
    "for label in unique_words:\n",
    "    \n",
    "#     X_out=X_t_data[int(label)-1]\n",
    "#     y_out=y_t_data[int(label)-1]\n",
    "\n",
    "    \n",
    "\n",
    "    # generate traget lables make others zero: one vs all\n",
    "    target = np.zeros((len(y_train),2),dtype=int)\n",
    "    for i,l_i in enumerate(y_train):\n",
    "        if(int(l_i)==int(label)):\n",
    "            target[i][0]=1\n",
    "        else: \n",
    "            target[i][1]=1\n",
    "    \n",
    "    print(int(label))\n",
    "        \n",
    "    # train model\n",
    "    nn_trainer = NNTrainer(input_n_cols=input_n_cols)\n",
    "    nn_trainer.train(X_train, target)\n",
    "    \n",
    "    nn_trainer.save_modle(folder_name, \"ada_girls_model_{}\".format(int(label)))\n",
    "    \n",
    "    # append model\n",
    "    nn_models.append((nn_trainer, label))\n",
    "    nn_trainer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVALUATE MODELS\n",
    "\n",
    "Given each test data, we run all the models on it data and pick the one with the best score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model with best score\n",
    "\n",
    "# as undersample data is marginal reduce the number of test data\n",
    "\n",
    "logprob_1 = np.array([m[0].predict_probability(X_test)[:,0] for m in nn_models]) ## prob of one gorup\n",
    "logprob_2 = np.array([m[0].predict_probability(X_test)[:,1] for m in nn_models]) ## prob of others group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_label = np.argmax(logprob_1, axis=0)\n",
    "# error = (predicted_label != y_test)\n",
    "# print('Overall test accuracy: %.2f percent' % (100 * (1-np.mean(error))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logprob_1=logprob_1.T\n",
    "logprob_2=logprob_2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "how to evaluate evaluate model:\n",
    "    select the ones with larget prob.\n",
    "    if prob of ones are euqal for any model then select the model with min others prob\n",
    "'''\n",
    " \n",
    "result=np.zeros((y_test.shape[0]), dtype=int)\n",
    "\n",
    "for i in range(y_test.shape[0]):\n",
    "    max_array=[]\n",
    "    max_n=-100\n",
    "    idx=1\n",
    "    max_min=100\n",
    "    for j in range(41):\n",
    "        max_array.append(logprob_1[i][j])\n",
    "        \n",
    "        if logprob_1[i][j]>max_n and logprob_1[i][j]>=.9:\n",
    "            max_n=logprob_1[i][j]\n",
    "            max_min=logprob_2[i][j]\n",
    "            idx=(j+1)   \n",
    "        if logprob_1[i][j]==max_n and logprob_2[i][j]<max_min:\n",
    "            max_n=logprob_1[i][j]\n",
    "            max_min=logprob_2[i][j]\n",
    "            idx=(j+1)\n",
    "            \n",
    "            \n",
    "    \n",
    "    #sort max array\n",
    "    max_array.sort()\n",
    "    \n",
    "    # compare result with the actual labels\n",
    "    if(int(y_test[i])==int(idx) and max_array[-1]-max_array[-2]>=0.5):\n",
    "        result[i]=1\n",
    "        \n",
    "        \n",
    "overall_acc = np.mean(result)*100\n",
    "print('Overall unseen test accuracy: %.2f percent' % overall_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy on unseen test data (one vs. all)**\n",
    "\n",
    "* Normal Accuracy: 99.32\n",
    "\n",
    "* Accuracy where (h1>=0.9): 98.57\n",
    "\n",
    "* Accuracy where (h1>=0.9 and h1-h2>=0.5): 98.07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy on unseen test ada girls data (ada girl model)**\n",
    "\n",
    "* Normal Accuracy: 95.31\n",
    "\n",
    "* Accuracy where (h1>=0.9): 91.66\n",
    "\n",
    "* Accuracy where (h1>=0.9 and h1-h2>=0.5): 90.63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CHECK GENERALIZATION ON DIFFERENT MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "in order to check generalization of model, we'll test data 40(40th word features) on model 1 (1 word's data)\n",
    "'''\n",
    "# random undersampling \n",
    "# X_out, y_out = ronadom_undersample(X_train, y_train, int(1))\n",
    "\n",
    "# oversmapling smote\n",
    "# X_out, y_out = smote_sampling(X_train, y_train, int(1))\n",
    "\n",
    "# oversampling multiply\n",
    "X_out, y_out = multiply_oversmaple(X_train, y_train, int(1))\n",
    "\n",
    "# shullfe data\n",
    "X_out, y_out = shuffle(X_out, y_out, random_state=0)\n",
    "\n",
    "target = np.zeros((len(y_out),2),dtype=int)\n",
    "\n",
    "for i,l_i in enumerate(y_out):\n",
    "    if(int(l_i)==40):\n",
    "        target[i][0]=1\n",
    "    else:         \n",
    "        target[i][1]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_result_41=nn_models[0][0].model_evaluate(X_out,target)\n",
    "print(\"%.2f%%\" % (model_1_result_41))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it seems not-targeted data on target model outputs a result with a marginal degree of certainty, 49.03%. This indicates that models trained can make good generalization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
