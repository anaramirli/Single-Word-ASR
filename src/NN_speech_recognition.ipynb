{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building NN for speech recogniton and optimize result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "from python_speech_features import mfcc, logfbank\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from keras.models import Sequential\n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "features_df = pd.read_csv('datagirl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train label and data\n",
    "all_labels = features_df.values[:,0]\n",
    "x_data = features_df.values[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare categorical target values (e.g [0,0,0,1,0])\n",
    "target = np.zeros((len(all_labels),41),dtype=int)\n",
    "for i,_ in enumerate(all_labels):\n",
    "    target[i][int(_)]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read ADA data\n",
    "features_df_ada = pd.read_csv('data41ADA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train label and data for ADA\n",
    "all_labels_ada = features_df_ada.values[:,0]\n",
    "x_data_ada = features_df_ada.values[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare categorical target values (e.g [0,0,0,1,0])\n",
    "target_ada = np.zeros((len(all_labels_ada),41),dtype=int)\n",
    "for i,_ in enumerate(all_labels_ada):\n",
    "    target_ada[i][int(_)]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_ada, target_ada = shuffle(x_data_ada, target_ada, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.vstack((x_data, x_data_ada[0:4500]))\n",
    "target = np.vstack((target, target_ada[0:4500]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training matrix: (6040, 2808)\n",
      "Size of testing matrix: (1067, 2808)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.15, random_state=0)\n",
    "\n",
    "for train_index, test_index in sss.split(x_data,target):\n",
    "    X_train, X_test = x_data[train_index], x_data[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    \n",
    "\n",
    "print('Size of training matrix:', X_train.shape)\n",
    "print('Size of testing matrix:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize train\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize test\n",
    "scaler = preprocessing.StandardScaler().fit(X_test)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get number of columns in training data\n",
    "n_cols = x_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#add layers to model\n",
    "model.add(Dense(200, activation='sigmoid', input_shape=(n_cols,)))\n",
    "model.add(Dense(200, activation='sigmoid'))\n",
    "model.add(Dense(41, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 200)               561800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 41)                8241      \n",
      "=================================================================\n",
      "Total params: 610,241\n",
      "Trainable params: 610,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model parameters\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4832 samples, validate on 1208 samples\n",
      "Epoch 1/20\n",
      "4832/4832 [==============================] - 5s 936us/step - loss: 2.2201e-07 - acc: 1.0000 - val_loss: 0.1216 - val_acc: 0.9776\n",
      "Epoch 2/20\n",
      "4832/4832 [==============================] - 4s 905us/step - loss: 2.0890e-07 - acc: 1.0000 - val_loss: 0.1220 - val_acc: 0.9776\n",
      "Epoch 3/20\n",
      "4832/4832 [==============================] - 5s 932us/step - loss: 1.9721e-07 - acc: 1.0000 - val_loss: 0.1223 - val_acc: 0.9776\n",
      "Epoch 4/20\n",
      "4832/4832 [==============================] - 5s 1ms/step - loss: 1.8766e-07 - acc: 1.0000 - val_loss: 0.1224 - val_acc: 0.9776\n",
      "Epoch 5/20\n",
      "4832/4832 [==============================] - 5s 1ms/step - loss: 1.7927e-07 - acc: 1.0000 - val_loss: 0.1229 - val_acc: 0.9776\n",
      "Epoch 6/20\n",
      "4832/4832 [==============================] - 6s 1ms/step - loss: 1.7187e-07 - acc: 1.0000 - val_loss: 0.1230 - val_acc: 0.9776\n",
      "Epoch 7/20\n",
      "4832/4832 [==============================] - 6s 1ms/step - loss: 1.6573e-07 - acc: 1.0000 - val_loss: 0.1231 - val_acc: 0.9776\n",
      "Epoch 8/20\n",
      "4832/4832 [==============================] - 6s 1ms/step - loss: 1.6050e-07 - acc: 1.0000 - val_loss: 0.1237 - val_acc: 0.9776\n",
      "Epoch 9/20\n",
      "4832/4832 [==============================] - 6s 1ms/step - loss: 1.5560e-07 - acc: 1.0000 - val_loss: 0.1236 - val_acc: 0.9776\n",
      "Epoch 10/20\n",
      "4832/4832 [==============================] - 6s 1ms/step - loss: 1.5198e-07 - acc: 1.0000 - val_loss: 0.1238 - val_acc: 0.9785- loss: 1.5207e-07 - acc:\n",
      "Epoch 11/20\n",
      "4832/4832 [==============================] - 5s 1ms/step - loss: 1.4874e-07 - acc: 1.0000 - val_loss: 0.1241 - val_acc: 0.978500\n",
      "Epoch 12/20\n",
      "4832/4832 [==============================] - 6s 1ms/step - loss: 1.4564e-07 - acc: 1.0000 - val_loss: 0.1243 - val_acc: 0.9785\n",
      "Epoch 13/20\n",
      "4832/4832 [==============================] - 5s 967us/step - loss: 1.4335e-07 - acc: 1.0000 - val_loss: 0.1245 - val_acc: 0.9785\n",
      "Epoch 14/20\n",
      "4832/4832 [==============================] - 5s 974us/step - loss: 1.4112e-07 - acc: 1.0000 - val_loss: 0.1246 - val_acc: 0.9785\n",
      "Epoch 15/20\n",
      "4832/4832 [==============================] - 6s 1ms/step - loss: 1.3928e-07 - acc: 1.0000 - val_loss: 0.1247 - val_acc: 0.9785\n",
      "Epoch 16/20\n",
      "4832/4832 [==============================] - 6s 1ms/step - loss: 1.3758e-07 - acc: 1.0000 - val_loss: 0.1250 - val_acc: 0.9785\n",
      "Epoch 17/20\n",
      "4832/4832 [==============================] - 5s 1ms/step - loss: 1.3621e-07 - acc: 1.0000 - val_loss: 0.1251 - val_acc: 0.9785\n",
      "Epoch 18/20\n",
      "4832/4832 [==============================] - 5s 1ms/step - loss: 1.3480e-07 - acc: 1.0000 - val_loss: 0.1251 - val_acc: 0.9785\n",
      "Epoch 19/20\n",
      "4832/4832 [==============================] - 5s 1ms/step - loss: 1.3369e-07 - acc: 1.0000 - val_loss: 0.1252 - val_acc: 0.9785\n",
      "Epoch 20/20\n",
      "4832/4832 [==============================] - 5s 1ms/step - loss: 1.3284e-07 - acc: 1.0000 - val_loss: 0.1253 - val_acc: 0.9785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cb0a635208>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=20,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 97.38%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_acc(X_test,y_test,h1,h2):\n",
    "    '''\n",
    "    how to evaluate evaluate model:\n",
    "        select the ones with larget prob.\n",
    "        if prob of ones are euqal for any model then select the model with min others prob\n",
    "    '''\n",
    "    prob = model.predict_proba(X_test)\n",
    "    predicted_label = np.argmax(y_test, axis=1)\n",
    "    result=np.zeros((y_test.shape[0]), dtype=int)\n",
    "\n",
    "    for i in range(y_test.shape[0]):\n",
    "        max_array=[]\n",
    "        max_n=-100\n",
    "        idx=0\n",
    "        for j in range(41):\n",
    "            max_array.append(prob[i][j])\n",
    "\n",
    "            if prob[i][j]>max_n and prob[i][j]>=h1:\n",
    "                max_n=prob[i][j]\n",
    "                idx=j   \n",
    "\n",
    "        #sort max array\n",
    "        max_array.sort()\n",
    "\n",
    "        # compare result with the actual labels\n",
    "        if(int(predicted_label[i])==int(idx) and max_array[-1]-max_array[-2]>=h2):\n",
    "            result[i]=1\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall unseen test accuracy: 96.06 percent\n"
     ]
    }
   ],
   "source": [
    "overall_acc = np.mean(calculate_acc(X_test,y_test,h1=.9,h2=.0))*100\n",
    "print('Overall unseen test accuracy: %.2f percent' % overall_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy on unseen test data (normal model)**\n",
    "\n",
    "* Normal Accuracy: 98.79\n",
    "\n",
    "* Accuracy where (h1>=0.9): 98.38\n",
    "\n",
    "* Accuracy where (h1>=0.9 and h1-h2>=0.5): 98.38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy on unseen test data (normal+ada model)**\n",
    "\n",
    "* Normal Accuracy: 98.61\n",
    "\n",
    "* Accuracy where (h1>=0.9): 97.84\n",
    "\n",
    "* Accuracy where (h1>=0.9 and h1-h2>=0.5): 97.81"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy on unseen test data (ada model girls)**\n",
    "\n",
    "* Normal Accuracy: 97.38\n",
    "\n",
    "* Accuracy where (h1>=0.9): 96.06\n",
    "\n",
    "* Accuracy where (h1>=0.9 and h1-h2>=0.5): 96.06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ADA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "features_df_ada = pd.read_csv('databoy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train label and data\n",
    "all_labels_ada = features_df_ada.values[:,0]\n",
    "x_data_ada = features_df_ada.values[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare categorical target values (e.g [0,0,0,1,0])\n",
    "target_ada = np.zeros((len(all_labels_ada),41),dtype=int)\n",
    "for i,_ in enumerate(all_labels_ada):\n",
    "    target_ada[i][int(_)]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize train\n",
    "# x_data_ada=x_data_ada[4500:]\n",
    "# target_ada=target_ada[4500:]\n",
    "\n",
    "x_data_ada, target_ada = shuffle(x_data_ada, target_ada, random_state=0)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(x_data_ada)\n",
    "x_data_ada=scaler.transform(x_data_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 76.22%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_data_ada, target_ada, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall unseen test accuracy: 69.21 percent\n"
     ]
    }
   ],
   "source": [
    "overall_acc = np.mean(calculate_acc(x_data_ada,target_ada,h1=.9,h2=.5))*100\n",
    "print('Overall unseen test accuracy: %.2f percent' % overall_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy on unseen test ada data (normal model)**\n",
    "\n",
    "* Normal Accuracy: 83.1\n",
    "\n",
    "* Accuracy where (h1>=0.9): 76.63\n",
    "\n",
    "* Accuracy where (h1>=0.9 and h1-h2>=0.5): 76.61"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy on unseen test ada data (normal + ada model)**\n",
    "\n",
    "* Normal Accuracy: 95.80\n",
    "\n",
    "* Accuracy where (h1>=0.9): 93.41\n",
    "\n",
    "* Accuracy where (h1>=0.9 and h1-h2>=0.5): 93.38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy on unseen test ada boys data (ada girl model)**\n",
    "\n",
    "* Normal Accuracy: 76.22\n",
    "\n",
    "* Accuracy where (h1>=0.9): 69.26\n",
    "\n",
    "* Accuracy where (h1>=0.9 and h1-h2>=0.5): 69.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
