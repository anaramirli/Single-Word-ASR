{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building NN for speech recogniton and optimize result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "from python_speech_features import mfcc, logfbank\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name=\"NNs/normal\"\n",
    "model_name=\"normal_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "train_df = pd.read_csv('data/normal/data41normal_train.csv')\n",
    "test_df = pd.read_csv('data/normal/data41normal_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     \"\"\"\n",
    "#     get data and return preprocessed data\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     train_df: train data\n",
    "#     test_df: test data\n",
    "#     label_increment: increment model index only for one vs. all models, default False\n",
    "#     categorical: categorical preperation of data, default True\n",
    "#     category_size: category size for catageorical preperation, default: 41\n",
    "#     normalize: normalize data, default True;\n",
    "    \n",
    "#     Return\n",
    "#     ------\n",
    "#     X_out, y_out\n",
    "#     \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = utils_prepare_data(train_df, category_size=41)\n",
    "X_test, y_test = utils_prepare_data(test_df, category_size=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training matrix: (18218, 2808)\n",
      "Size of testing matrix: (3215, 2808)\n"
     ]
    }
   ],
   "source": [
    "print('Size of training matrix:', X_train.shape)\n",
    "print('Size of testing matrix:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out = train_df.values[:,0]\n",
    "X_out = train_df.values[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18218, 2809)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BUILD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get number of columns in training data\n",
    "n_cols = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#add layers to model\n",
    "model.add(Dense(200, activation='sigmoid', input_shape=(n_cols,)))\n",
    "model.add(Dense(200, activation='sigmoid'))\n",
    "model.add(Dense(41, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 200)               561800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 41)                8241      \n",
      "=================================================================\n",
      "Total params: 610,241\n",
      "Trainable params: 610,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model parameters\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14574 samples, validate on 3644 samples\n",
      "Epoch 1/50\n",
      "14574/14574 [==============================] - 16s 1ms/step - loss: 0.9229 - acc: 0.8623 - val_loss: 0.1848 - val_acc: 0.9742\n",
      "Epoch 2/50\n",
      "14574/14574 [==============================] - 12s 844us/step - loss: 0.0898 - acc: 0.9899 - val_loss: 0.0881 - val_acc: 0.9877\n",
      "Epoch 3/50\n",
      "14574/14574 [==============================] - 11s 766us/step - loss: 0.0304 - acc: 0.9975 - val_loss: 0.0642 - val_acc: 0.9885\n",
      "Epoch 4/50\n",
      "14574/14574 [==============================] - 14s 971us/step - loss: 0.0133 - acc: 0.9993 - val_loss: 0.0502 - val_acc: 0.9907\n",
      "Epoch 5/50\n",
      "14574/14574 [==============================] - 14s 947us/step - loss: 0.0066 - acc: 0.9997 - val_loss: 0.0442 - val_acc: 0.9915\n",
      "Epoch 6/50\n",
      "14574/14574 [==============================] - 16s 1ms/step - loss: 0.0041 - acc: 0.9997 - val_loss: 0.0438 - val_acc: 0.9890\n",
      "Epoch 7/50\n",
      "14574/14574 [==============================] - 13s 919us/step - loss: 0.0027 - acc: 0.9999 - val_loss: 0.0429 - val_acc: 0.9896\n",
      "Epoch 8/50\n",
      "14574/14574 [==============================] - 13s 889us/step - loss: 0.0016 - acc: 0.9999 - val_loss: 0.0409 - val_acc: 0.9904\n",
      "Epoch 9/50\n",
      "14574/14574 [==============================] - 13s 904us/step - loss: 0.0016 - acc: 0.9998 - val_loss: 0.0422 - val_acc: 0.9904\n",
      "Epoch 10/50\n",
      "14574/14574 [==============================] - 13s 901us/step - loss: 9.2453e-04 - acc: 0.9999 - val_loss: 0.0452 - val_acc: 0.9898\n",
      "Epoch 11/50\n",
      "14574/14574 [==============================] - 13s 914us/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0436 - val_acc: 0.9898\n",
      "Epoch 12/50\n",
      "14574/14574 [==============================] - 13s 888us/step - loss: 6.7133e-04 - acc: 0.9999 - val_loss: 0.0417 - val_acc: 0.9901\n",
      "Epoch 13/50\n",
      "14574/14574 [==============================] - 13s 880us/step - loss: 4.2296e-04 - acc: 0.9999 - val_loss: 0.0449 - val_acc: 0.9898\n",
      "Epoch 14/50\n",
      "14574/14574 [==============================] - 13s 879us/step - loss: 8.3026e-04 - acc: 0.9999 - val_loss: 0.0472 - val_acc: 0.9890\n",
      "Epoch 15/50\n",
      "14574/14574 [==============================] - 13s 884us/step - loss: 1.9293e-04 - acc: 0.9999 - val_loss: 0.0455 - val_acc: 0.9898\n",
      "Epoch 16/50\n",
      "14574/14574 [==============================] - 13s 897us/step - loss: 1.7722e-04 - acc: 0.9999 - val_loss: 0.0446 - val_acc: 0.9896\n",
      "Epoch 17/50\n",
      "14574/14574 [==============================] - 13s 893us/step - loss: 6.1767e-04 - acc: 0.9998 - val_loss: 0.0441 - val_acc: 0.9909\n",
      "Epoch 18/50\n",
      "14574/14574 [==============================] - 13s 900us/step - loss: 1.5740e-04 - acc: 0.9999 - val_loss: 0.0452 - val_acc: 0.9898\n",
      "Epoch 19/50\n",
      "14574/14574 [==============================] - 13s 890us/step - loss: 4.4830e-05 - acc: 1.0000 - val_loss: 0.0439 - val_acc: 0.9907\n",
      "Epoch 20/50\n",
      "14574/14574 [==============================] - 13s 891us/step - loss: 2.4502e-05 - acc: 1.0000 - val_loss: 0.0460 - val_acc: 0.9898\n",
      "Epoch 21/50\n",
      "14574/14574 [==============================] - 13s 911us/step - loss: 0.0178 - acc: 0.9949 - val_loss: 0.1216 - val_acc: 0.9651\n",
      "Epoch 22/50\n",
      "14574/14574 [==============================] - 13s 912us/step - loss: 0.0155 - acc: 0.9954 - val_loss: 0.0758 - val_acc: 0.9822\n",
      "Epoch 23/50\n",
      "14574/14574 [==============================] - 14s 995us/step - loss: 0.0013 - acc: 0.9999 - val_loss: 0.0551 - val_acc: 0.9882\n",
      "Epoch 24/50\n",
      "14574/14574 [==============================] - 16s 1ms/step - loss: 3.2002e-04 - acc: 1.0000 - val_loss: 0.0532 - val_acc: 0.9890\n",
      "Epoch 25/50\n",
      "14574/14574 [==============================] - 14s 977us/step - loss: 2.0450e-04 - acc: 1.0000 - val_loss: 0.0534 - val_acc: 0.9893\n",
      "Epoch 26/50\n",
      "14574/14574 [==============================] - 14s 949us/step - loss: 2.9728e-04 - acc: 0.9999 - val_loss: 0.0534 - val_acc: 0.9890\n",
      "Epoch 27/50\n",
      "14574/14574 [==============================] - 15s 1ms/step - loss: 6.7278e-04 - acc: 0.9999 - val_loss: 0.0554 - val_acc: 0.9887\n",
      "Epoch 28/50\n",
      "14574/14574 [==============================] - 15s 1ms/step - loss: 2.4045e-04 - acc: 0.9999 - val_loss: 0.0531 - val_acc: 0.9893\n",
      "Epoch 29/50\n",
      "14574/14574 [==============================] - 14s 969us/step - loss: 4.1994e-04 - acc: 0.9999 - val_loss: 0.0532 - val_acc: 0.9896\n",
      "Epoch 30/50\n",
      "14574/14574 [==============================] - 14s 953us/step - loss: 3.8425e-04 - acc: 0.9999 - val_loss: 0.0571 - val_acc: 0.9885\n",
      "Epoch 31/50\n",
      "14574/14574 [==============================] - 14s 941us/step - loss: 2.9101e-04 - acc: 0.9999 - val_loss: 0.0545 - val_acc: 0.9898\n",
      "Epoch 32/50\n",
      "14574/14574 [==============================] - 14s 933us/step - loss: 2.8768e-04 - acc: 0.9999 - val_loss: 0.0557 - val_acc: 0.9890\n",
      "Epoch 33/50\n",
      "14574/14574 [==============================] - 14s 940us/step - loss: 5.3997e-04 - acc: 0.9999 - val_loss: 0.0565 - val_acc: 0.9879\n",
      "Epoch 34/50\n",
      "14574/14574 [==============================] - 14s 944us/step - loss: 3.6620e-05 - acc: 1.0000 - val_loss: 0.0566 - val_acc: 0.9898\n",
      "Epoch 35/50\n",
      "14574/14574 [==============================] - 14s 932us/step - loss: 1.1153e-05 - acc: 1.0000 - val_loss: 0.0565 - val_acc: 0.9896\n",
      "Epoch 36/50\n",
      "14574/14574 [==============================] - 14s 932us/step - loss: 7.6699e-06 - acc: 1.0000 - val_loss: 0.0566 - val_acc: 0.98987.1886e-06 \n",
      "Epoch 37/50\n",
      "14574/14574 [==============================] - 14s 943us/step - loss: 5.8413e-06 - acc: 1.0000 - val_loss: 0.0569 - val_acc: 0.9898\n",
      "Epoch 38/50\n",
      "14574/14574 [==============================] - 14s 936us/step - loss: 4.4860e-06 - acc: 1.0000 - val_loss: 0.0570 - val_acc: 0.9898\n",
      "Epoch 39/50\n",
      "14574/14574 [==============================] - 14s 931us/step - loss: 3.4330e-06 - acc: 1.0000 - val_loss: 0.0576 - val_acc: 0.9904\n",
      "Epoch 40/50\n",
      "14574/14574 [==============================] - 14s 928us/step - loss: 2.6690e-06 - acc: 1.0000 - val_loss: 0.0580 - val_acc: 0.9907\n",
      "Epoch 41/50\n",
      "14574/14574 [==============================] - 14s 942us/step - loss: 2.0230e-06 - acc: 1.0000 - val_loss: 0.0587 - val_acc: 0.9904\n",
      "Epoch 42/50\n",
      "14574/14574 [==============================] - 14s 942us/step - loss: 1.5186e-06 - acc: 1.0000 - val_loss: 0.0589 - val_acc: 0.9904\n",
      "Epoch 43/50\n",
      "14574/14574 [==============================] - 14s 934us/step - loss: 1.1419e-06 - acc: 1.0000 - val_loss: 0.0592 - val_acc: 0.9904\n",
      "Epoch 44/50\n",
      "14574/14574 [==============================] - 14s 942us/step - loss: 9.7503e-07 - acc: 1.0000 - val_loss: 0.0596 - val_acc: 0.9901\n",
      "Epoch 45/50\n",
      "14574/14574 [==============================] - 14s 990us/step - loss: 6.6559e-07 - acc: 1.0000 - val_loss: 0.0604 - val_acc: 0.9901\n",
      "Epoch 46/50\n",
      "14574/14574 [==============================] - 18s 1ms/step - loss: 5.8435e-07 - acc: 1.0000 - val_loss: 0.0606 - val_acc: 0.9901\n",
      "Epoch 47/50\n",
      "14574/14574 [==============================] - 14s 984us/step - loss: 0.0227 - acc: 0.9936 - val_loss: 0.0974 - val_acc: 0.9772\n",
      "Epoch 48/50\n",
      "14574/14574 [==============================] - 14s 956us/step - loss: 0.0083 - acc: 0.9970 - val_loss: 0.0902 - val_acc: 0.9811\n",
      "Epoch 49/50\n",
      "14574/14574 [==============================] - 14s 976us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0718 - val_acc: 0.9844\n",
      "Epoch 50/50\n",
      "14574/14574 [==============================] - 14s 950us/step - loss: 1.4870e-04 - acc: 1.0000 - val_loss: 0.0688 - val_acc: 0.9849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ecaf2049e8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=20,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 98.9424572%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"%s: %.7f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_acc(X_test,y_test,h1,h2):\n",
    "    '''\n",
    "    how to evaluate evaluate model:\n",
    "        select the ones with larget prob.\n",
    "        if prob of ones are euqal for any model then select the model with min others prob\n",
    "    '''\n",
    "    prob = model.predict_proba(X_test)\n",
    "    predicted_label = np.argmax(y_test, axis=1)\n",
    "    result=np.zeros((y_test.shape[0]), dtype=int)\n",
    "\n",
    "    for i in range(y_test.shape[0]):\n",
    "        max_array=[]\n",
    "        max_n=-100\n",
    "        idx=0\n",
    "        for j in range(41):\n",
    "            max_array.append(prob[i][j])\n",
    "\n",
    "            if prob[i][j]>max_n and prob[i][j]>=h1:\n",
    "                max_n=prob[i][j]\n",
    "                idx=j   \n",
    "\n",
    "        #sort max array\n",
    "        max_array.sort()\n",
    "\n",
    "        # compare result with the actual labels\n",
    "        if(int(predicted_label[i])==int(idx) and max_array[-1]-max_array[-2]>=h2):\n",
    "            result[i]=1\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall unseen test accuracy: 98.94 percent\n"
     ]
    }
   ],
   "source": [
    "overall_acc = np.mean(calculate_acc(X_test,y_test,h1=.0,h2=.0))*100\n",
    "print('Overall unseen test accuracy: %.2f percent' % overall_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a HDF5 file 'my_model.h5'\n",
    "model.save('models/{path}/{model}.h5'.format(path=folder_name,model=model_name))\n",
    "# Deletes the existing model\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a compiled model identical to the previous one\n",
    "model = load_model('models/{path}/{model}.h5'.format(path=folder_name, model=model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_acc = np.mean(calculate_acc(X_test,y_test,h1=.9,h2=.5))*100\n",
    "print('Overall unseen test accuracy: %.2f percent' % overall_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy on unseen test data (normal model)**\n",
    "\n",
    "* Normal Accuracy: 98.94\n",
    "\n",
    "* Accuracy where (h1>=0.9): 98.51\n",
    "\n",
    "* Accuracy where (h1>=0.9 and h1-h2>=0.5): 98.51"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy on unseen test data (normal+ada model)**\n",
    "\n",
    "* Normal Accuracy: 98.61\n",
    "\n",
    "* Accuracy where (h1>=0.9): 97.84\n",
    "\n",
    "* Accuracy where (h1>=0.9 and h1-h2>=0.5): 97.81"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy on unseen test data (ada model girls)**\n",
    "\n",
    "* Normal Accuracy: 97.28\n",
    "\n",
    "* Accuracy where (h1>=0.9): 94.85\n",
    "\n",
    "* Accuracy where (h1>=0.9 and h1-h2>=0.5): 94.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ADA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "features_df_ada = pd.read_csv('databoy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train label and data\n",
    "all_labels_ada = features_df_ada.values[:,0]\n",
    "x_data_ada = features_df_ada.values[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare categorical target values (e.g [0,0,0,1,0])\n",
    "target_ada = np.zeros((len(all_labels_ada),41),dtype=int)\n",
    "for i,_ in enumerate(all_labels_ada):\n",
    "    target_ada[i][int(_)]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize train\n",
    "# x_data_ada=x_data_ada[4500:]\n",
    "# target_ada=target_ada[4500:]\n",
    "\n",
    "x_data_ada, target_ada = shuffle(x_data_ada, target_ada, random_state=0)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(x_data_ada)\n",
    "x_data_ada=scaler.transform(x_data_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_data_ada, target_ada, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_acc = np.mean(calculate_acc(x_data_ada,target_ada,h1=.9,h2=.5))*100\n",
    "print('Overall unseen test accuracy: %.2f percent' % overall_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy on unseen test ada data (normal model)**\n",
    "\n",
    "* Normal Accuracy: 84.04\n",
    "\n",
    "* Accuracy where (h1>=0.9): 78.29\n",
    "\n",
    "* Accuracy where (h1>=0.9 and h1-h2>=0.5): 78.21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy on unseen test ada data (normal + ada model)**\n",
    "\n",
    "* Normal Accuracy: 95.80\n",
    "\n",
    "* Accuracy where (h1>=0.9): 93.41\n",
    "\n",
    "* Accuracy where (h1>=0.9 and h1-h2>=0.5): 93.38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy on unseen test ada boys data (ada girl model)**\n",
    "\n",
    "* Normal Accuracy: 76.07\n",
    "\n",
    "* Accuracy where (h1>=0.9): 66.82\n",
    "\n",
    "* Accuracy where (h1>=0.9 and h1-h2>=0.5): 66.72"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
