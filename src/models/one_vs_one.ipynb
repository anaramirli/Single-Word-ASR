{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "from python_speech_features import mfcc, logfbank\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from keras.regularizers import l1,l2\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our utils functions\n",
    "from src.utils import *\n",
    "\n",
    "# our classes\n",
    "from classes.PreprocessData import *\n",
    "from classes.EvaluateModel import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name=\"1_vs_1/mix\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "train_df = pd.read_csv('data/mix/data41mix_train.csv')\n",
    "test_df = pd.read_csv('data/mix/data41mix_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_dict={0:1,1:6,2:11,3:13,4:15,5:17,6:20,7:22,8:25,9:36}\n",
    "\n",
    "class_size=41\n",
    "label_dict={}\n",
    "for i in range(class_size):\n",
    "    label_dict[i]=i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize preprocess class\n",
    "preprocess = PreprocessData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split data, normalize, shuffle\n",
    "X_train, y_train = preprocess.preprocess_data(train_df, normalize=False)\n",
    "X_test, y_test = preprocess.preprocess_data(test_df, normalize=False)\n",
    "# new_test=test_df.loc[test_df['# target'].isin([1, 6, 11, 13, 15, 17, 20, 22, 25, 36])]\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training matrix: (26027, 2808)\n",
      "Size of testing matrix: (4593, 2808)\n"
     ]
    }
   ],
   "source": [
    "print('Size of training matrix:', X_train.shape)\n",
    "print('Size of testing matrix:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0}\n"
     ]
    }
   ],
   "source": [
    "# get unique labesl\n",
    "unique_words = set(y_test)\n",
    "print(unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to handle NN processing\n",
    "class NNTrainer(object):  \n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    layer_activation: activation function for input and hidden layers\n",
    "    covariance_type: activation function of end layer\n",
    "    input_n_cols: numver of columns of input layer\n",
    "    optimizer_function: optimization function\n",
    "    loss_function: loss functions\n",
    "    metrics_v: metric for evaluation result\n",
    "    epochs_n: number of epoches to update train weights\n",
    "    batch_size_n: batch size of fitted data\n",
    "    validation_split_n: ratio of validation split in traning \n",
    "    \n",
    "    choice of parameters depends on the data. \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, layer_activation='relu', end_layer_activation='softmax',input_n_cols=2808,\n",
    "                 optimizer_function='adam',loss_function='categorical_crossentropy',metrics_v='accuracy',\n",
    "                epochs_n=15, batch_size_n=32, validation_split_n=0.2):\n",
    "        \n",
    "        # initialize variables\n",
    "        self.layer_activation = layer_activation\n",
    "        self.end_layer_activation = end_layer_activation\n",
    "        self.input_n_cols = input_n_cols\n",
    "        self.optimizer_function = optimizer_function\n",
    "        self.loss_function = loss_function\n",
    "        self.metrics_v = metrics_v\n",
    "        self.epochs_n = epochs_n\n",
    "        self.batch_size_n =batch_size_n\n",
    "        self.validation_split_n = validation_split_n\n",
    "        \n",
    "        \n",
    "        # define model\n",
    "        self.model = Sequential()\n",
    "        #add layers to model and initialize\n",
    "        self.model.add(Dense(50, activation=self.layer_activation, input_shape=(self.input_n_cols,)))\n",
    "        self.model.add(Dropout(0.2))\n",
    "#         self.model.add(Dense(200, activation=self.layer_activation, input_shape=(self.input_n_cols,)))\n",
    "#         self.model.add(Dense(200, activation=self.layer_activation, input_shape=(self.input_n_cols,)))\n",
    "\n",
    "        self.model.add(Dense(2, activation=self.end_layer_activation))\n",
    "        \n",
    "        # compile model\n",
    "        self.model.compile(optimizer=self.optimizer_function, \n",
    "                           loss=self.loss_function,metrics=[self.metrics_v])\n",
    "            \n",
    "    #train mode\n",
    "    def train(self, X_train, y_train):\n",
    "        # ingonre divisin by 0\n",
    "        # np.seterr(all='ignore') \n",
    "        #train model\n",
    "        self.model.fit(X_train, y_train, epochs=self.epochs_n,\n",
    "                       batch_size=self.batch_size_n,validation_split=self.validation_split_n, verbose=0)\n",
    "         \n",
    "    # run the model on new data and get score\n",
    "    def predict_probability(self, X_test):\n",
    "        scores = self.model.predict_proba(X_test)\n",
    "        return scores\n",
    "\n",
    "    \n",
    "    # return model\n",
    "    def model_evaluate(self, X_test, y_test):\n",
    "        scores = self.model.evaluate(X_test, y_test, verbose=1)\n",
    "        return scores[1]*100\n",
    "    \n",
    "    # return model\n",
    "    def get_nn_model():\n",
    "        return self.model\n",
    "    \n",
    "    def save_modle(self, folder_name, model_name):\n",
    "        # Creates a HDF5 file 'my_model.h5'\n",
    "        self.model.save('models/{path}/{model}.h5'.format(path=folder_name,model=model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_group = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_group = {}\n",
    "prob_group_2 = {}\n",
    "for i in range(len(label_dict)):\n",
    "    prob_group[i]=[]\n",
    "    prob_group_2[i]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [],\n",
       " 1: [],\n",
       " 2: [],\n",
       " 3: [],\n",
       " 4: [],\n",
       " 5: [],\n",
       " 6: [],\n",
       " 7: [],\n",
       " 8: [],\n",
       " 9: [],\n",
       " 10: [],\n",
       " 11: [],\n",
       " 12: [],\n",
       " 13: [],\n",
       " 14: [],\n",
       " 15: [],\n",
       " 16: [],\n",
       " 17: [],\n",
       " 18: [],\n",
       " 19: [],\n",
       " 20: [],\n",
       " 21: [],\n",
       " 22: [],\n",
       " 23: [],\n",
       " 24: [],\n",
       " 25: [],\n",
       " 26: [],\n",
       " 27: [],\n",
       " 28: [],\n",
       " 29: [],\n",
       " 30: [],\n",
       " 31: [],\n",
       " 32: [],\n",
       " 33: [],\n",
       " 34: [],\n",
       " 35: [],\n",
       " 36: [],\n",
       " 37: [],\n",
       " 38: [],\n",
       " 39: [],\n",
       " 40: []}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(label_dict)):\n",
    "    \n",
    "    for j in range(i+1, len(label_dict)):\n",
    "        \n",
    "        save_label = str(label_dict[i])+\"-\"+str(label_dict[j])\n",
    "#         print(save_label)\n",
    "                \n",
    "        \n",
    "        new_train_df=train_df.loc[train_df['# target'].isin([label_dict[i],label_dict[j]])]\n",
    "\n",
    "        X_train, y_train = preprocess.preprocess_data(new_train_df, normalize=False)\n",
    "        X_train=scaler.transform(X_train)\n",
    "        \n",
    "        target = np.zeros((len(y_train),2),dtype=int)\n",
    "        \n",
    "        for y_t_i,y_l_i in enumerate(y_train):\n",
    "            \n",
    "            if(int(y_l_i)==int(label_dict[i])):\n",
    "                target[y_t_i][0]=1\n",
    "            else: \n",
    "                target[y_t_i][1]=1\n",
    "                \n",
    "        \n",
    "        # train model\n",
    "        nn_trainer = NNTrainer()\n",
    "        nn_trainer.train(X_train, target)\n",
    "\n",
    "        nn_trainer.save_modle(folder_name, \"{}\".format(save_label))\n",
    "\n",
    "        # append model\n",
    "        model_group[save_label]=nn_trainer\n",
    "        \n",
    "        nn_trainer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0,10):\n",
    "    \n",
    "#     logprob = np.array([(model[0].predict_probability(X_test)[:,1],model[0].predict_probability(X_test)[:,0])[i<=model_i] for model_i, model in enumerate(model_group[i])]) ## prob of one gorup\n",
    "#     prob_group[i] = logprob\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-1\n",
      "0-2\n",
      "0-3\n",
      "0-4\n",
      "0-5\n",
      "0-6\n",
      "0-7\n",
      "0-8\n",
      "0-9\n",
      "0-10\n",
      "0-11\n",
      "0-12\n",
      "0-13\n",
      "0-14\n",
      "0-15\n",
      "0-16\n",
      "0-17\n",
      "0-18\n",
      "0-19\n",
      "0-20\n",
      "0-21\n",
      "0-22\n",
      "0-23\n",
      "0-24\n",
      "0-25\n",
      "0-26\n",
      "0-27\n",
      "0-28\n",
      "0-29\n",
      "0-30\n",
      "0-31\n",
      "0-32\n",
      "0-33\n",
      "0-34\n",
      "0-35\n",
      "0-36\n",
      "0-37\n",
      "0-38\n",
      "0-39\n",
      "0-40\n",
      "1-2\n",
      "1-3\n",
      "1-4\n",
      "1-5\n",
      "1-6\n",
      "1-7\n",
      "1-8\n",
      "1-9\n",
      "1-10\n",
      "1-11\n",
      "1-12\n",
      "1-13\n",
      "1-14\n",
      "1-15\n",
      "1-16\n",
      "1-17\n",
      "1-18\n",
      "1-19\n",
      "1-20\n",
      "1-21\n",
      "1-22\n",
      "1-23\n",
      "1-24\n",
      "1-25\n",
      "1-26\n",
      "1-27\n",
      "1-28\n",
      "1-29\n",
      "1-30\n",
      "1-31\n",
      "1-32\n",
      "1-33\n",
      "1-34\n",
      "1-35\n",
      "1-36\n",
      "1-37\n",
      "1-38\n",
      "1-39\n",
      "1-40\n",
      "2-3\n",
      "2-4\n",
      "2-5\n",
      "2-6\n",
      "2-7\n",
      "2-8\n",
      "2-9\n",
      "2-10\n",
      "2-11\n",
      "2-12\n",
      "2-13\n",
      "2-14\n",
      "2-15\n",
      "2-16\n",
      "2-17\n",
      "2-18\n",
      "2-19\n",
      "2-20\n",
      "2-21\n",
      "2-22\n",
      "2-23\n",
      "2-24\n",
      "2-25\n",
      "2-26\n",
      "2-27\n",
      "2-28\n",
      "2-29\n",
      "2-30\n",
      "2-31\n",
      "2-32\n",
      "2-33\n",
      "2-34\n",
      "2-35\n",
      "2-36\n",
      "2-37\n",
      "2-38\n",
      "2-39\n",
      "2-40\n",
      "3-4\n",
      "3-5\n",
      "3-6\n",
      "3-7\n",
      "3-8\n",
      "3-9\n",
      "3-10\n",
      "3-11\n",
      "3-12\n",
      "3-13\n",
      "3-14\n",
      "3-15\n",
      "3-16\n",
      "3-17\n",
      "3-18\n",
      "3-19\n",
      "3-20\n",
      "3-21\n",
      "3-22\n",
      "3-23\n",
      "3-24\n",
      "3-25\n",
      "3-26\n",
      "3-27\n",
      "3-28\n",
      "3-29\n",
      "3-30\n",
      "3-31\n",
      "3-32\n",
      "3-33\n",
      "3-34\n",
      "3-35\n",
      "3-36\n",
      "3-37\n",
      "3-38\n",
      "3-39\n",
      "3-40\n",
      "4-5\n",
      "4-6\n",
      "4-7\n",
      "4-8\n",
      "4-9\n",
      "4-10\n",
      "4-11\n",
      "4-12\n",
      "4-13\n",
      "4-14\n",
      "4-15\n",
      "4-16\n",
      "4-17\n",
      "4-18\n",
      "4-19\n",
      "4-20\n",
      "4-21\n",
      "4-22\n",
      "4-23\n",
      "4-24\n",
      "4-25\n",
      "4-26\n",
      "4-27\n",
      "4-28\n",
      "4-29\n",
      "4-30\n",
      "4-31\n",
      "4-32\n",
      "4-33\n",
      "4-34\n",
      "4-35\n",
      "4-36\n",
      "4-37\n",
      "4-38\n",
      "4-39\n",
      "4-40\n",
      "5-6\n",
      "5-7\n",
      "5-8\n",
      "5-9\n",
      "5-10\n",
      "5-11\n",
      "5-12\n",
      "5-13\n",
      "5-14\n",
      "5-15\n",
      "5-16\n",
      "5-17\n",
      "5-18\n",
      "5-19\n",
      "5-20\n",
      "5-21\n",
      "5-22\n",
      "5-23\n",
      "5-24\n",
      "5-25\n",
      "5-26\n",
      "5-27\n",
      "5-28\n",
      "5-29\n",
      "5-30\n",
      "5-31\n",
      "5-32\n",
      "5-33\n",
      "5-34\n",
      "5-35\n",
      "5-36\n",
      "5-37\n",
      "5-38\n",
      "5-39\n",
      "5-40\n",
      "6-7\n",
      "6-8\n",
      "6-9\n",
      "6-10\n",
      "6-11\n",
      "6-12\n",
      "6-13\n",
      "6-14\n",
      "6-15\n",
      "6-16\n",
      "6-17\n",
      "6-18\n",
      "6-19\n",
      "6-20\n",
      "6-21\n",
      "6-22\n",
      "6-23\n",
      "6-24\n",
      "6-25\n",
      "6-26\n",
      "6-27\n",
      "6-28\n",
      "6-29\n",
      "6-30\n",
      "6-31\n",
      "6-32\n",
      "6-33\n",
      "6-34\n",
      "6-35\n",
      "6-36\n",
      "6-37\n",
      "6-38\n",
      "6-39\n",
      "6-40\n",
      "7-8\n",
      "7-9\n",
      "7-10\n",
      "7-11\n",
      "7-12\n",
      "7-13\n",
      "7-14\n",
      "7-15\n",
      "7-16\n",
      "7-17\n",
      "7-18\n",
      "7-19\n",
      "7-20\n",
      "7-21\n",
      "7-22\n",
      "7-23\n",
      "7-24\n",
      "7-25\n",
      "7-26\n",
      "7-27\n",
      "7-28\n",
      "7-29\n",
      "7-30\n",
      "7-31\n",
      "7-32\n",
      "7-33\n",
      "7-34\n",
      "7-35\n",
      "7-36\n",
      "7-37\n",
      "7-38\n",
      "7-39\n",
      "7-40\n",
      "8-9\n",
      "8-10\n",
      "8-11\n",
      "8-12\n",
      "8-13\n",
      "8-14\n",
      "8-15\n",
      "8-16\n",
      "8-17\n",
      "8-18\n",
      "8-19\n",
      "8-20\n",
      "8-21\n",
      "8-22\n",
      "8-23\n",
      "8-24\n",
      "8-25\n",
      "8-26\n",
      "8-27\n",
      "8-28\n",
      "8-29\n",
      "8-30\n",
      "8-31\n",
      "8-32\n",
      "8-33\n",
      "8-34\n",
      "8-35\n",
      "8-36\n",
      "8-37\n",
      "8-38\n",
      "8-39\n",
      "8-40\n",
      "9-10\n",
      "9-11\n",
      "9-12\n",
      "9-13\n",
      "9-14\n",
      "9-15\n",
      "9-16\n",
      "9-17\n",
      "9-18\n",
      "9-19\n",
      "9-20\n",
      "9-21\n",
      "9-22\n",
      "9-23\n",
      "9-24\n",
      "9-25\n",
      "9-26\n",
      "9-27\n",
      "9-28\n",
      "9-29\n",
      "9-30\n",
      "9-31\n",
      "9-32\n",
      "9-33\n",
      "9-34\n",
      "9-35\n",
      "9-36\n",
      "9-37\n",
      "9-38\n",
      "9-39\n",
      "9-40\n",
      "10-11\n",
      "10-12\n",
      "10-13\n",
      "10-14\n",
      "10-15\n",
      "10-16\n",
      "10-17\n",
      "10-18\n",
      "10-19\n",
      "10-20\n",
      "10-21\n",
      "10-22\n",
      "10-23\n",
      "10-24\n",
      "10-25\n",
      "10-26\n",
      "10-27\n",
      "10-28\n",
      "10-29\n",
      "10-30\n",
      "10-31\n",
      "10-32\n",
      "10-33\n",
      "10-34\n",
      "10-35\n",
      "10-36\n",
      "10-37\n",
      "10-38\n",
      "10-39\n",
      "10-40\n",
      "11-12\n",
      "11-13\n",
      "11-14\n",
      "11-15\n",
      "11-16\n",
      "11-17\n",
      "11-18\n",
      "11-19\n",
      "11-20\n",
      "11-21\n",
      "11-22\n",
      "11-23\n",
      "11-24\n",
      "11-25\n",
      "11-26\n",
      "11-27\n",
      "11-28\n",
      "11-29\n",
      "11-30\n",
      "11-31\n",
      "11-32\n",
      "11-33\n",
      "11-34\n",
      "11-35\n",
      "11-36\n",
      "11-37\n",
      "11-38\n",
      "11-39\n",
      "11-40\n",
      "12-13\n",
      "12-14\n",
      "12-15\n",
      "12-16\n",
      "12-17\n",
      "12-18\n",
      "12-19\n",
      "12-20\n",
      "12-21\n",
      "12-22\n",
      "12-23\n",
      "12-24\n",
      "12-25\n",
      "12-26\n",
      "12-27\n",
      "12-28\n",
      "12-29\n",
      "12-30\n",
      "12-31\n",
      "12-32\n",
      "12-33\n",
      "12-34\n",
      "12-35\n",
      "12-36\n",
      "12-37\n",
      "12-38\n",
      "12-39\n",
      "12-40\n",
      "13-14\n",
      "13-15\n",
      "13-16\n",
      "13-17\n",
      "13-18\n",
      "13-19\n",
      "13-20\n",
      "13-21\n",
      "13-22\n",
      "13-23\n",
      "13-24\n",
      "13-25\n",
      "13-26\n",
      "13-27\n",
      "13-28\n",
      "13-29\n",
      "13-30\n",
      "13-31\n",
      "13-32\n",
      "13-33\n",
      "13-34\n",
      "13-35\n",
      "13-36\n",
      "13-37\n",
      "13-38\n",
      "13-39\n",
      "13-40\n",
      "14-15\n",
      "14-16\n",
      "14-17\n",
      "14-18\n",
      "14-19\n",
      "14-20\n",
      "14-21\n",
      "14-22\n",
      "14-23\n",
      "14-24\n",
      "14-25\n",
      "14-26\n",
      "14-27\n",
      "14-28\n",
      "14-29\n",
      "14-30\n",
      "14-31\n",
      "14-32\n",
      "14-33\n",
      "14-34\n",
      "14-35\n",
      "14-36\n",
      "14-37\n",
      "14-38\n",
      "14-39\n",
      "14-40\n",
      "15-16\n",
      "15-17\n",
      "15-18\n",
      "15-19\n",
      "15-20\n",
      "15-21\n",
      "15-22\n",
      "15-23\n",
      "15-24\n",
      "15-25\n",
      "15-26\n",
      "15-27\n",
      "15-28\n",
      "15-29\n",
      "15-30\n",
      "15-31\n",
      "15-32\n",
      "15-33\n",
      "15-34\n",
      "15-35\n",
      "15-36\n",
      "15-37\n",
      "15-38\n",
      "15-39\n",
      "15-40\n",
      "16-17\n",
      "16-18\n",
      "16-19\n",
      "16-20\n",
      "16-21\n",
      "16-22\n",
      "16-23\n",
      "16-24\n",
      "16-25\n",
      "16-26\n",
      "16-27\n",
      "16-28\n",
      "16-29\n",
      "16-30\n",
      "16-31\n",
      "16-32\n",
      "16-33\n",
      "16-34\n",
      "16-35\n",
      "16-36\n",
      "16-37\n",
      "16-38\n",
      "16-39\n",
      "16-40\n",
      "17-18\n",
      "17-19\n",
      "17-20\n",
      "17-21\n",
      "17-22\n",
      "17-23\n",
      "17-24\n",
      "17-25\n",
      "17-26\n",
      "17-27\n",
      "17-28\n",
      "17-29\n",
      "17-30\n",
      "17-31\n",
      "17-32\n",
      "17-33\n",
      "17-34\n",
      "17-35\n",
      "17-36\n",
      "17-37\n",
      "17-38\n",
      "17-39\n",
      "17-40\n",
      "18-19\n",
      "18-20\n",
      "18-21\n",
      "18-22\n",
      "18-23\n",
      "18-24\n",
      "18-25\n",
      "18-26\n",
      "18-27\n",
      "18-28\n",
      "18-29\n",
      "18-30\n",
      "18-31\n",
      "18-32\n",
      "18-33\n",
      "18-34\n",
      "18-35\n",
      "18-36\n",
      "18-37\n",
      "18-38\n",
      "18-39\n",
      "18-40\n",
      "19-20\n",
      "19-21\n",
      "19-22\n",
      "19-23\n",
      "19-24\n",
      "19-25\n",
      "19-26\n",
      "19-27\n",
      "19-28\n",
      "19-29\n",
      "19-30\n",
      "19-31\n",
      "19-32\n",
      "19-33\n",
      "19-34\n",
      "19-35\n",
      "19-36\n",
      "19-37\n",
      "19-38\n",
      "19-39\n",
      "19-40\n",
      "20-21\n",
      "20-22\n",
      "20-23\n",
      "20-24\n",
      "20-25\n",
      "20-26\n",
      "20-27\n",
      "20-28\n",
      "20-29\n",
      "20-30\n",
      "20-31\n",
      "20-32\n",
      "20-33\n",
      "20-34\n",
      "20-35\n",
      "20-36\n",
      "20-37\n",
      "20-38\n",
      "20-39\n",
      "20-40\n",
      "21-22\n",
      "21-23\n",
      "21-24\n",
      "21-25\n",
      "21-26\n",
      "21-27\n",
      "21-28\n",
      "21-29\n",
      "21-30\n",
      "21-31\n",
      "21-32\n",
      "21-33\n",
      "21-34\n",
      "21-35\n",
      "21-36\n",
      "21-37\n",
      "21-38\n",
      "21-39\n",
      "21-40\n",
      "22-23\n",
      "22-24\n",
      "22-25\n",
      "22-26\n",
      "22-27\n",
      "22-28\n",
      "22-29\n",
      "22-30\n",
      "22-31\n",
      "22-32\n",
      "22-33\n",
      "22-34\n",
      "22-35\n",
      "22-36\n",
      "22-37\n",
      "22-38\n",
      "22-39\n",
      "22-40\n",
      "23-24\n",
      "23-25\n",
      "23-26\n",
      "23-27\n",
      "23-28\n",
      "23-29\n",
      "23-30\n",
      "23-31\n",
      "23-32\n",
      "23-33\n",
      "23-34\n",
      "23-35\n",
      "23-36\n",
      "23-37\n",
      "23-38\n",
      "23-39\n",
      "23-40\n",
      "24-25\n",
      "24-26\n",
      "24-27\n",
      "24-28\n",
      "24-29\n",
      "24-30\n",
      "24-31\n",
      "24-32\n",
      "24-33\n",
      "24-34\n",
      "24-35\n",
      "24-36\n",
      "24-37\n",
      "24-38\n",
      "24-39\n",
      "24-40\n",
      "25-26\n",
      "25-27\n",
      "25-28\n",
      "25-29\n",
      "25-30\n",
      "25-31\n",
      "25-32\n",
      "25-33\n",
      "25-34\n",
      "25-35\n",
      "25-36\n",
      "25-37\n",
      "25-38\n",
      "25-39\n",
      "25-40\n",
      "26-27\n",
      "26-28\n",
      "26-29\n",
      "26-30\n",
      "26-31\n",
      "26-32\n",
      "26-33\n",
      "26-34\n",
      "26-35\n",
      "26-36\n",
      "26-37\n",
      "26-38\n",
      "26-39\n",
      "26-40\n",
      "27-28\n",
      "27-29\n",
      "27-30\n",
      "27-31\n",
      "27-32\n",
      "27-33\n",
      "27-34\n",
      "27-35\n",
      "27-36\n",
      "27-37\n",
      "27-38\n",
      "27-39\n",
      "27-40\n",
      "28-29\n",
      "28-30\n",
      "28-31\n",
      "28-32\n",
      "28-33\n",
      "28-34\n",
      "28-35\n",
      "28-36\n",
      "28-37\n",
      "28-38\n",
      "28-39\n",
      "28-40\n",
      "29-30\n",
      "29-31\n",
      "29-32\n",
      "29-33\n",
      "29-34\n",
      "29-35\n",
      "29-36\n",
      "29-37\n",
      "29-38\n",
      "29-39\n",
      "29-40\n",
      "30-31\n",
      "30-32\n",
      "30-33\n",
      "30-34\n",
      "30-35\n",
      "30-36\n",
      "30-37\n",
      "30-38\n",
      "30-39\n",
      "30-40\n",
      "31-32\n",
      "31-33\n",
      "31-34\n",
      "31-35\n",
      "31-36\n",
      "31-37\n",
      "31-38\n",
      "31-39\n",
      "31-40\n",
      "32-33\n",
      "32-34\n",
      "32-35\n",
      "32-36\n",
      "32-37\n",
      "32-38\n",
      "32-39\n",
      "32-40\n",
      "33-34\n",
      "33-35\n",
      "33-36\n",
      "33-37\n",
      "33-38\n",
      "33-39\n",
      "33-40\n",
      "34-35\n",
      "34-36\n",
      "34-37\n",
      "34-38\n",
      "34-39\n",
      "34-40\n",
      "35-36\n",
      "35-37\n",
      "35-38\n",
      "35-39\n",
      "35-40\n",
      "36-37\n",
      "36-38\n",
      "36-39\n",
      "36-40\n",
      "37-38\n",
      "37-39\n",
      "37-40\n",
      "38-39\n",
      "38-40\n",
      "39-40\n"
     ]
    }
   ],
   "source": [
    " def atoi(text):\n",
    "            return int(text) if str(text).isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split('(\\d+)', int(text) if str(text).isdigit() else text) ]\n",
    "\n",
    "models=[]\n",
    "\n",
    "files_list = os.listdir('models/1_vs_1/mix')\n",
    "files_list.sort(key=natural_keys)\n",
    "\n",
    "for w in files_list:\n",
    "# check wheter files is .h5 or no\n",
    "    if (w.find('.h5')!=-1):\n",
    "        model_name=w\n",
    "        model_group[model_name[:-3]] = models.append(load_model('models/1_vs_1/mix'+'/{model}'.format(model=model_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(label_dict)):\n",
    "    for j in range(i+1, len(label_dict)):\n",
    "        \n",
    "        save_label = str(label_dict[i])+\"-\"+str(label_dict[j])\n",
    "        model=model_group[save_label]\n",
    "        \n",
    "        logprob_1=model.predict_proba(X_test)[:,0]\n",
    "        logprob_2=model.predict_proba(X_test)[:,1]\n",
    "        \n",
    "        prob_group[i].append(logprob_1)\n",
    "        prob_group[j].append(logprob_2)\n",
    "        \n",
    "        prob_group_2[i].append(logprob_2)\n",
    "        prob_group_2[j].append(logprob_1)\n",
    "        \n",
    "for i in range(len(label_dict)):\n",
    "    prob_group[i]=np.array(prob_group[i]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=np.array\n",
    "\n",
    "mean_l = []\n",
    "max_l = []\n",
    "\n",
    "mean_l_2 = []\n",
    "min_l_2 = []\n",
    "for i in range(0,len(label_dict)):\n",
    "    mean_l.append(np.mean(prob_group[i],axis=1))\n",
    "    max_l.append(np.max(prob_group[i],axis=1))\n",
    "    \n",
    "    mean_l_2.append(np.mean(prob_group_2[i],axis=1))\n",
    "    min_l_2.append(np.min(prob_group_2[i],axis=1))\n",
    "\n",
    "result_mean=np.vstack(mean_l).T\n",
    "result_max=np.vstack(max_l).T\n",
    "\n",
    "result_mean_2=np.vstack(mean_l).T\n",
    "result_min_2=np.vstack(max_l).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "how to evaluate evaluate model:\n",
    "    select the ones with larget prob.\n",
    "    if prob of ones are euqal for any model then select the model with min others prob\n",
    "'''\n",
    "logprob_1=result_mean\n",
    "logprob_2=result_mean_2\n",
    "result=np.zeros((y_test.shape[0]), dtype=int)\n",
    "\n",
    "for i in range(y_test.shape[0]):\n",
    "    max_array=[]\n",
    "    max_n=-100\n",
    "    idx=1\n",
    "    max_min=100\n",
    "    for j in range(len(label_dict)):\n",
    "        max_array.append(logprob_1[i][j])\n",
    "        if logprob_1[i][j]>max_n:\n",
    "            max_n=logprob_1[i][j]\n",
    "            max_min=logprob_2[i][j]\n",
    "            idx=j\n",
    "            \n",
    "        if logprob_1[i][j]==max_n and logprob_2[i][j]<max_min:\n",
    "            max_n=logprob_1[i][j]\n",
    "            max_min=logprob_2[i][j]\n",
    "            idx=j\n",
    "       \n",
    "    #sort max array\n",
    "    max_array.sort()\n",
    "    \n",
    "    # compare result with the actual labels\n",
    "    if(int(y_test[i])==int(label_dict[idx]) and max_array[-1]>=.0 and max_array[-1]-max_array[-2]>=0.0):\n",
    "        result[i]=1\n",
    "        \n",
    "        \n",
    "overall_acc = np.mean(result)*100\n",
    "print('Overall unseen test accuracy: %.4f percent' % overall_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer: 1, node: 50\n",
    "\n",
    "Max: 71.8579\n",
    "\n",
    "Mean: 99.36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With new approach: logprob1, logprob2 / Layer: 1, node: 50\n",
    "    \n",
    "Mean: 99.76\n",
    "\n",
    "Max: 76.68"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
